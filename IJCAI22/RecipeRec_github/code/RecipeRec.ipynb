{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "# import lmdb\n",
    "import gensim\n",
    "import heapq\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import torchfile\n",
    "from torch.nn import init\n",
    "import dgl.function as fn\n",
    "from dgl.utils import expand_as_pair\n",
    "# from dgl.nn import EdgeWeightNorm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  mps\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = \"mps\"\n",
    "\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "Ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # top@K performance\n",
    "n_test_negs = 100 # number of negative recipes for each test user\n",
    "dataset_folder = '../data/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph ...\n",
      "graph:  Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 135353, ('user', 'u-r', 'recipe'): 135353},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
     ]
    }
   ],
   "source": [
    "def get_graph():\n",
    "    print('generating graph ...')\n",
    "    edge_src, edge_dst, r_i_edge_weight = torch.load(dataset_folder+'/edge_r2i_src_dst_weight.pt')\n",
    "    recipe_edge_src, recipe_edge_dst, recipe_edge_weight = torch.load(dataset_folder+'/edge_r2r_src_and_dst_and_weight.pt')\n",
    "    ingre_edge_src, ingre_edge_dst, ingre_edge_weight = torch.load(dataset_folder+'/edge_i2i_src_and_dst_and_weight.pt')\n",
    "    all_u2r_src_dst_weight, train_u2r_src_dst_weight, val_u2r_src_dst_weight, test_u2r_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
    "    u_rate_r_edge_src, u_rate_r_edge_dst, u_rate_r_edge_weight = all_u2r_src_dst_weight\n",
    "    \n",
    "    # nodes and edges\n",
    "    graph = dgl.heterograph({\n",
    "        ('recipe', 'r-i', 'ingredient'): (edge_src, edge_dst),\n",
    "        ('ingredient', 'i-r', 'recipe'): (edge_dst, edge_src),\n",
    "        ('recipe', 'r-r', 'recipe'): (recipe_edge_src, recipe_edge_dst),\n",
    "        ('ingredient', 'i-i', 'ingredient'): (ingre_edge_src, ingre_edge_dst),\n",
    "        ('user', 'u-r', 'recipe'): (u_rate_r_edge_src, u_rate_r_edge_dst),\n",
    "        ('recipe', 'r-u', 'user'): (u_rate_r_edge_dst, u_rate_r_edge_src)\n",
    "    })\n",
    "\n",
    "    # edge weight\n",
    "    graph.edges['r-i'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
    "    graph.edges['i-r'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
    "    graph.edges['r-r'].data['weight'] = torch.FloatTensor(recipe_edge_weight)\n",
    "    graph.edges['i-i'].data['weight'] = torch.FloatTensor(ingre_edge_weight)\n",
    "    graph.edges['u-r'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
    "    graph.edges['r-u'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
    "    \n",
    "    # node features\n",
    "    recipe_nodes_avg_instruction_features = torch.load(dataset_folder+'/recipe_nodes_avg_instruction_features.pt')\n",
    "    ingredient_nodes_nutrient_features_minus1 = torch.load(dataset_folder+'/ingredient_nodes_nutrient_features.pt')\n",
    "    graph.nodes['recipe'].data['avg_instr_feature'] = recipe_nodes_avg_instruction_features\n",
    "    graph.nodes['ingredient'].data['nutrient_feature'] = ingredient_nodes_nutrient_features_minus1\n",
    "    graph.nodes['user'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(7959, 300))\n",
    "    graph.nodes['recipe'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(68794, 1024))\n",
    "\n",
    "    return graph\n",
    "\n",
    "graph = get_graph()\n",
    "print('graph: ', graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all_src:  135353\n",
      "length of train_eids:  119435\n",
      "length of val_eids:  7959\n",
      "length of test_eids:  7959\n"
     ]
    }
   ],
   "source": [
    "all_src_dst_weight, train_src_dst_weight, val_src_dst_weight, test_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
    "all_src, all_dst, all_weight = all_src_dst_weight\n",
    "train_src, train_dst, train_weight = train_src_dst_weight\n",
    "val_src, val_dst, val_weight = val_src_dst_weight\n",
    "test_src, test_dst, test_weight = test_src_dst_weight\n",
    "\n",
    "train_eids = graph.edge_ids(train_src, train_dst, etype='u-r')\n",
    "val_eids = graph.edge_ids(val_src, val_dst, etype='u-r')\n",
    "test_eids = graph.edge_ids(test_src, test_dst, etype='u-r')\n",
    "val_eids_r2u = graph.edge_ids(val_dst, val_src, etype='r-u')\n",
    "test_eids_r2u = graph.edge_ids(test_dst, test_src, etype='r-u')\n",
    "print('length of all_src: ', len(all_src))\n",
    "print('length of train_eids: ', len(train_eids))\n",
    "print('length of val_eids: ', len(val_eids))\n",
    "print('length of test_eids: ', len(test_eids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training graph: \n",
      "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 119435, ('user', 'u-r', 'recipe'): 119435},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n",
      "\n",
      "val graph: \n",
      "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 127394, ('user', 'u-r', 'recipe'): 127394},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
     ]
    }
   ],
   "source": [
    "# get train_graph and val_graph\n",
    "train_graph = graph.clone()\n",
    "train_graph.remove_edges(torch.cat([val_eids, test_eids]), etype='u-r')\n",
    "train_graph.remove_edges(torch.cat([val_eids_r2u, test_eids_r2u]), etype='r-u')\n",
    "print('training graph: ')\n",
    "print(train_graph)\n",
    "print()\n",
    "\n",
    "val_graph = graph.clone()\n",
    "val_graph.remove_edges(test_eids, etype='u-r')\n",
    "val_graph.remove_edges(test_eids, etype='r-u')\n",
    "print('val graph: ')\n",
    "print(val_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7959/7959 [00:00<00:00, 26304.67it/s]\n",
      "100%|██████████| 7959/7959 [00:00<00:00, 62003.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of batches in train_edgeloader:  117\n",
      "# of batches in val_edgeloader:  63\n",
      "# of batches in test_edgeloader:  63\n",
      "\n",
      "blocks:  [Block(num_src_nodes={'ingredient': 6520, 'recipe': 61672, 'user': 5801},\n",
      "      num_dst_nodes={'ingredient': 3655, 'recipe': 27051, 'user': 3013},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 47115, ('ingredient', 'i-r', 'recipe'): 177203, ('recipe', 'r-i', 'ingredient'): 50318, ('recipe', 'r-r', 'recipe'): 251693, ('recipe', 'r-u', 'user'): 35255, ('user', 'u-r', 'recipe'): 52446},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')]), Block(num_src_nodes={'ingredient': 3655, 'recipe': 27051, 'user': 3013},\n",
      "      num_dst_nodes={'ingredient': 0, 'recipe': 5888, 'user': 684},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 0, ('ingredient', 'i-r', 'recipe'): 39643, ('recipe', 'r-i', 'ingredient'): 0, ('recipe', 'r-r', 'recipe'): 31678, ('recipe', 'r-u', 'user'): 10379, ('user', 'u-r', 'recipe'): 10108},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])]\n"
     ]
    }
   ],
   "source": [
    "# edge dataloaders\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([20, 20])\n",
    "neg_sampler = dgl.dataloading.negative_sampler.Uniform(5)\n",
    "\n",
    "class test_NegativeSampler(object):\n",
    "    def __init__(self, g, k):\n",
    "        # get the negatives\n",
    "        self.user2negs_100_dict = {}\n",
    "        filename = dataset_folder+'/test_negatives_100.txt'\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in tqdm(lines):\n",
    "                if line == None or line == \"\":\n",
    "                    continue\n",
    "                line = line[:-1] # remove \\n\n",
    "                user = int(line.split('\\t')[0].split(',')[0][1:])\n",
    "                negs = [int(neg) for neg in line.split('\\t')[1:]]\n",
    "                self.user2negs_100_dict[user] = negs\n",
    "                \n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, g, eids_dict):\n",
    "        result_dict = {}\n",
    "        for etype, eids in eids_dict.items():\n",
    "            src, _ = g.find_edges(eids, etype=etype)\n",
    "            dst = []\n",
    "            for each_src in src:\n",
    "                dst.extend(self.user2negs_100_dict[int(each_src)][:self.k])\n",
    "            dst = torch.tensor(dst)\n",
    "            src = src.repeat_interleave(self.k)\n",
    "            result_dict[etype] = (src, dst)\n",
    "        return result_dict\n",
    "    \n",
    "test_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
    "test_train_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
    "    \n",
    "train_collator = dgl.dataloading.EdgeCollator(\n",
    "    train_graph, {'u-r': train_graph.edge_ids(train_src, train_dst, etype='u-r')}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=neg_sampler)\n",
    "val_collator = dgl.dataloading.EdgeCollator(\n",
    "    val_graph, {'u-r': val_graph.edge_ids(val_src, val_dst, etype='u-r')}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=neg_sampler)\n",
    "test_collator = dgl.dataloading.EdgeCollator(\n",
    "    graph, {('user', 'u-r', 'recipe'): test_eids}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=test_neg_sampler)\n",
    "\n",
    "train_edgeloader = torch.utils.data.DataLoader(\n",
    "    train_collator.dataset, collate_fn=train_collator.collate,\n",
    "    batch_size=1024, shuffle=True, drop_last=False, num_workers=0)\n",
    "val_edgeloader = torch.utils.data.DataLoader(\n",
    "    val_collator.dataset, collate_fn=val_collator.collate,\n",
    "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
    "test_edgeloader = torch.utils.data.DataLoader(\n",
    "    test_collator.dataset, collate_fn=test_collator.collate,\n",
    "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "print('# of batches in train_edgeloader: ', len(train_edgeloader))\n",
    "print('# of batches in val_edgeloader: ', len(val_edgeloader))\n",
    "print('# of batches in test_edgeloader: ', len(test_edgeloader))\n",
    "print()\n",
    "\n",
    "for input_nodes, pos_pair_graph, neg_pair_graph, blocks in train_edgeloader:\n",
    "    print('blocks: ', blocks)\n",
    "    break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68794/68794 [00:06<00:00, 11321.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingre_neighbor_tensor:  torch.Size([68794, 33])\n",
      "ingre_length_tensor:  torch.Size([68794])\n",
      "total_length_index_list:  68795\n",
      "total_ingre_neighbor_tensor:  torch.Size([454941])\n"
     ]
    }
   ],
   "source": [
    "# get ingre neighbors for each recipe nodes\n",
    "def get_recipe2ingreNeighbor_dict():\n",
    "    max_length = 33\n",
    "    out = {}\n",
    "    neighbor_list = []\n",
    "    ingre_length_list = []\n",
    "    total_length_index_list = []\n",
    "    total_ingre_neighbor_list = []\n",
    "    total_length_index = 0\n",
    "    total_length_index_list.append(total_length_index)\n",
    "    for recipeNodeID in tqdm(range(graph.number_of_nodes('recipe'))):\n",
    "        _, succs = graph.out_edges(recipeNodeID, etype='r-i')\n",
    "        succs_list = list(set(succs.tolist()))\n",
    "        total_ingre_neighbor_list.extend(succs_list)\n",
    "        cur_length = len(succs_list)\n",
    "        ingre_length_list.append(cur_length)\n",
    "        \n",
    "        total_length_index += cur_length\n",
    "        total_length_index_list.append(total_length_index)\n",
    "        while len(succs_list) < max_length:\n",
    "            succs_list.append(77733)\n",
    "        neighbor_list.append(succs_list)\n",
    "\n",
    "    ingre_neighbor_tensor = torch.tensor(neighbor_list)\n",
    "    ingre_length_tensor = torch.tensor(ingre_length_list)\n",
    "    total_ingre_neighbor_tensor = torch.tensor(total_ingre_neighbor_list)\n",
    "    return ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor\n",
    "\n",
    "ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor = get_recipe2ingreNeighbor_dict()\n",
    "print('ingre_neighbor_tensor: ', ingre_neighbor_tensor.shape)\n",
    "print('ingre_length_tensor: ', ingre_length_tensor.shape)\n",
    "print('total_length_index_list: ', len(total_length_index_list))\n",
    "print('total_ingre_neighbor_tensor: ', total_ingre_neighbor_tensor.shape)\n",
    "\n",
    "def find(tensor, values):\n",
    "    return torch.nonzero(tensor[..., None] == values)\n",
    "\n",
    "# example of find()\n",
    "# a = torch.tensor([0, 10, 20, 30])\n",
    "# b = torch.tensor([[ 0, 30, 20,  10, 77733],[ 0, 30, 20,  10, 77733]])\n",
    "# find(b, a)[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient_neighbors_all_embeddings(blocks, output_nodes, secondToLast_ingre):\n",
    "    ingreNodeIDs = blocks[1].srcdata['_ID']['ingredient']\n",
    "    recipeNodeIDs = output_nodes\n",
    "    batch_ingre_neighbors = ingre_neighbor_tensor[recipeNodeIDs].to(device)\n",
    "    batch_ingre_length = ingre_length_tensor[recipeNodeIDs]\n",
    "    valid_batch_ingre_neighbors = find(batch_ingre_neighbors, ingreNodeIDs)[:, 2]\n",
    "    \n",
    "    # based on valid_batch_ingre_neighbors each row index\n",
    "    _, valid_batch_ingre_length = torch.unique(find(batch_ingre_neighbors, ingreNodeIDs)[:, 0], return_counts=True)\n",
    "    batch_sum_ingre_length = np.cumsum(valid_batch_ingre_length.cpu())\n",
    "    \n",
    "    total_ingre_emb = None\n",
    "    for i in range(len(recipeNodeIDs)):\n",
    "        if i == 0:\n",
    "            recipeNode_ingres = valid_batch_ingre_neighbors[0:batch_sum_ingre_length[i]]\n",
    "            a = secondToLast_ingre[recipeNode_ingres]\n",
    "        else:\n",
    "            recipeNode_ingres = valid_batch_ingre_neighbors[batch_sum_ingre_length[i-1]:batch_sum_ingre_length[i]]\n",
    "            a = secondToLast_ingre[recipeNode_ingres]\n",
    "    \n",
    "        # all ingre instead of average\n",
    "        a_rows = a.shape[0]\n",
    "        a_columns = a.shape[1]\n",
    "        max_rows = 5\n",
    "        if a_rows < max_rows:\n",
    "            a = torch.cat([a, torch.zeros(max_rows-a_rows, a_columns).to(device)])\n",
    "        else:\n",
    "            a = a[:max_rows, :]\n",
    "        \n",
    "        if total_ingre_emb == None:\n",
    "            total_ingre_emb = a.unsqueeze(0)\n",
    "        else:\n",
    "            total_ingre_emb = torch.cat([total_ingre_emb,a.unsqueeze(0)], dim = 0)\n",
    "            if torch.isnan(total_ingre_emb).any():\n",
    "                print('Error!')\n",
    "\n",
    "    return total_ingre_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Scaled Dot-Product Attention.\"\"\"\n",
    "\n",
    "    def __init__(self, temperature):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"\n",
    "        It is equivariant to permutations\n",
    "        of the batch dimension (`b`).\n",
    "\n",
    "        It is equivariant to permutations of the\n",
    "        second dimension of the queries (`n`).\n",
    "\n",
    "        It is invariant to permutations of the\n",
    "        second dimension of keys and values (`m`).\n",
    "\n",
    "        Arguments:\n",
    "            queries: a float tensor with shape [b, n, d].\n",
    "            keys: a float tensor with shape [b, m, d].\n",
    "            values: a float tensor with shape [b, m, d'].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d'].\n",
    "        \"\"\"\n",
    "\n",
    "        attention = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        attention = self.softmax(attention / self.temperature)\n",
    "        # it has shape [b, n, m]\n",
    "\n",
    "        return torch.bmm(attention, values)\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, dimension of queries and values.\n",
    "                It is assumed that input and\n",
    "                output dimensions are the same.\n",
    "            h: an integer, number of heads.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert d % h == 0\n",
    "        self.h = h\n",
    "\n",
    "        # everything is projected to this dimension\n",
    "        p = d // h\n",
    "\n",
    "        self.project_queries = nn.Linear(d, d)\n",
    "        self.project_keys = nn.Linear(d, d)\n",
    "        self.project_values = nn.Linear(d, d)\n",
    "        self.concatenation = nn.Linear(d, d)\n",
    "        self.attention = Attention(temperature=p**0.5)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            queries: a float tensor with shape [b, n, d].\n",
    "            keys: a float tensor with shape [b, m, d].\n",
    "            values: a float tensor with shape [b, m, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.h\n",
    "        b, n, d = queries.size()\n",
    "        _, m, _ = keys.size()\n",
    "        p = d // h\n",
    "\n",
    "        queries = self.project_queries(queries)  # shape [b, n, d]\n",
    "        keys = self.project_keys(keys)  # shape [b, m, d]\n",
    "        values = self.project_values(values)  # shape [b, m, d]\n",
    "\n",
    "        queries = queries.view(b, n, h, p)\n",
    "        keys = keys.view(b, m, h, p)\n",
    "        values = values.view(b, m, h, p)\n",
    "\n",
    "        queries = queries.permute(2, 0, 1, 3).contiguous().view(h * b, n, p)\n",
    "        keys = keys.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
    "        values = values.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
    "\n",
    "        output = self.attention(queries, keys, values)  # shape [h * b, n, p]\n",
    "        output = output.view(h, b, n, p)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(b, n, d)\n",
    "        output = self.concatenation(output)  # shape [b, n, d]\n",
    "\n",
    "        return output\n",
    "\n",
    "class RFF(nn.Module):\n",
    "    \"\"\"\n",
    "    Row-wise FeedForward layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiheadAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h, rff):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            h: an integer, number of heads.\n",
    "            rff: a module, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.multihead = MultiheadAttention(d, h)\n",
    "        self.layer_norm1 = nn.LayerNorm(d)\n",
    "        self.layer_norm2 = nn.LayerNorm(d)\n",
    "        self.rff = rff\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        It is equivariant to permutations of the\n",
    "        second dimension of tensor x (`n`).\n",
    "\n",
    "        It is invariant to permutations of the\n",
    "        second dimension of tensor y (`m`).\n",
    "\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "            y: a float tensor with shape [b, m, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        h = self.layer_norm1(x + self.multihead(x, y, y))\n",
    "        return self.layer_norm2(h + self.rff(h))\n",
    "\n",
    "class SetAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h, rff):\n",
    "        super().__init__()\n",
    "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        return self.mab(x, x)\n",
    "\n",
    "class InducedSetAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, m, h, rff1, rff2):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            m: an integer, number of inducing points.\n",
    "            h: an integer, number of heads.\n",
    "            rff1, rff2: modules, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mab1 = MultiheadAttentionBlock(d, h, rff1)\n",
    "        self.mab2 = MultiheadAttentionBlock(d, h, rff2)\n",
    "        self.inducing_points = nn.Parameter(torch.randn(1, m, d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        b = x.size(0)\n",
    "        p = self.inducing_points\n",
    "        p = p.repeat([b, 1, 1])  # shape [b, m, d]\n",
    "        h = self.mab1(p, x)  # shape [b, m, d]\n",
    "        return self.mab2(x, h)\n",
    "\n",
    "class PoolingMultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d, k, h, rff):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            k: an integer, number of seed vectors.\n",
    "            h: an integer, number of heads.\n",
    "            rff: a module, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
    "        self.seed_vectors = nn.Parameter(torch.randn(1, k, d))\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            z: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, k, d].\n",
    "        \"\"\"\n",
    "        b = z.size(0)\n",
    "        s = self.seed_vectors\n",
    "        s = s.repeat([b, 1, 1])  # random seed vector: shape [b, k, d]\n",
    "\n",
    "        output = self.mab(s, z)\n",
    "        # print('PoolingMultiheadAttention', output.shape)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set transformer for ingredient representation\n",
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            in_dimension: an integer.  # 2\n",
    "            out_dimension: an integer. # 5 * K\n",
    "        \"\"\"\n",
    "        super(SetTransformer, self).__init__()\n",
    "        in_dimension = 46 # 300\n",
    "        out_dimension = 128 # 600\n",
    "\n",
    "        d = in_dimension\n",
    "        m = 46  # number of inducing points\n",
    "        h = 2  # 4 # number of heads\n",
    "        k = 4  # number of seed vectors\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d)),\n",
    "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d))\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            PoolingMultiheadAttention(d, k, h, RFF(d)),\n",
    "            SetAttentionBlock(d, h, RFF(d))\n",
    "        )\n",
    "\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            PoolingMultiheadAttention(d, k, h, RFF(d))\n",
    "        )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            SetAttentionBlock(d, h, RFF(d))\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(k * d, out_dimension),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [batch, n, in_dimension].\n",
    "        Returns:\n",
    "            a float tensor with shape [batch, out_dimension].\n",
    "        \"\"\"\n",
    "        x = self.encoder(x) # x = self.encoder(cut_x) # shape [batch, batch_max_len, d]\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder(x)  # shape [batch, k, d]\n",
    "\n",
    "        b, k, d = x.shape\n",
    "        x = x.view(b, k * d)\n",
    "\n",
    "        y = self.predictor(x)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_HeteroGraphConv(nn.Module):\n",
    "    def __init__(self, mods, aggregate='sum'):\n",
    "        super(custom_HeteroGraphConv, self).__init__()\n",
    "        self.mods = nn.ModuleDict(mods)\n",
    "        # Do not break if graph has 0-in-degree nodes.\n",
    "        # Because there is no general rule to add self-loop for heterograph.\n",
    "        for _, v in self.mods.items():\n",
    "            set_allow_zero_in_degree_fn = getattr(v, 'set_allow_zero_in_degree', None)\n",
    "            if callable(set_allow_zero_in_degree_fn):\n",
    "                set_allow_zero_in_degree_fn(True)\n",
    "        if isinstance(aggregate, str):\n",
    "            self.agg_fn = get_aggregate_fn(aggregate)\n",
    "        else:\n",
    "            self.agg_fn = aggregate\n",
    "\n",
    "    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):\n",
    "        if mod_args is None:\n",
    "            mod_args = {}\n",
    "        if mod_kwargs is None:\n",
    "            mod_kwargs = {}\n",
    "        outputs = {nty : [] for nty in g.dsttypes}\n",
    "        if isinstance(inputs, tuple) or g.is_block:\n",
    "            if isinstance(inputs, tuple):\n",
    "                src_inputs, dst_inputs = inputs\n",
    "            else:\n",
    "                src_inputs = inputs\n",
    "                dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
    "\n",
    "            for stype, etype, dtype in g.canonical_etypes:\n",
    "                rel_graph = g[stype, etype, dtype]\n",
    "                if rel_graph.number_of_edges() == 0:\n",
    "                    continue\n",
    "                if stype not in src_inputs or dtype not in dst_inputs:\n",
    "                    continue\n",
    "                dstdata = self.mods[etype](\n",
    "                    rel_graph,\n",
    "                    (src_inputs[stype], dst_inputs[dtype], mod_kwargs),\n",
    "                    *mod_args.get(etype, ())\n",
    "                    )\n",
    "                outputs[dtype].append(dstdata)\n",
    "        else:\n",
    "            for stype, etype, dtype in g.canonical_etypes:\n",
    "                rel_graph = g[stype, etype, dtype]\n",
    "                if rel_graph.number_of_edges() == 0:\n",
    "                    continue\n",
    "                if stype not in inputs:\n",
    "                    continue\n",
    "                dstdata = self.mods[etype](\n",
    "                    rel_graph,\n",
    "                    (inputs[stype], inputs[dtype], mod_kwargs),\n",
    "                    *mod_args.get(etype, ())\n",
    "                    )\n",
    "                outputs[dtype].append(dstdata)\n",
    "        rsts = {}\n",
    "        for nty, alist in outputs.items():\n",
    "            if len(alist) != 0:\n",
    "                rsts[nty] = self.agg_fn(alist, nty)\n",
    "        return rsts\n",
    "\n",
    "def _max_reduce_func(inputs, dim):\n",
    "    return torch.max(inputs, dim=dim)[0]\n",
    "\n",
    "def _min_reduce_func(inputs, dim):\n",
    "    return torch.min(inputs, dim=dim)[0]\n",
    "\n",
    "def _sum_reduce_func(inputs, dim):\n",
    "    return torch.sum(inputs, dim=dim)\n",
    "\n",
    "def _mean_reduce_func(inputs, dim):\n",
    "    return torch.mean(inputs, dim=dim)\n",
    "\n",
    "def _stack_agg_func(inputs, dsttype):\n",
    "    if len(inputs) == 0:\n",
    "        return None\n",
    "    return torch.stack(inputs, dim=1)\n",
    "\n",
    "def _agg_func(inputs, dsttype, fn):\n",
    "    if len(inputs) == 0:\n",
    "        return None\n",
    "    stacked = torch.stack(inputs, dim=0)\n",
    "    return fn(stacked, dim=0)\n",
    "\n",
    "def get_aggregate_fn(agg):\n",
    "    if agg == 'sum':\n",
    "        fn = _sum_reduce_func\n",
    "    elif agg == 'max':\n",
    "        fn = _max_reduce_func\n",
    "    elif agg == 'min':\n",
    "        fn = _min_reduce_func\n",
    "    elif agg == 'mean':\n",
    "        fn = _mean_reduce_func\n",
    "    elif agg == 'stack':\n",
    "        fn = None  # will not be called\n",
    "    else:\n",
    "        raise DGLError('Invalid cross type aggregator. Must be one of '\n",
    "                       '\"sum\", \"max\", \"min\", \"mean\" or \"stack\". But got \"%s\"' % agg)\n",
    "    if agg == 'stack':\n",
    "        return _stack_agg_func\n",
    "    else:\n",
    "        return partial(_agg_func, fn=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata['x'] = x\n",
    "            edge_subgraph.apply_edges(dgl.function.u_dot_v('x', 'x', 'score'), etype='u-r')\n",
    "            return edge_subgraph.edata['score'][('user', 'u-r', 'recipe')].squeeze()\n",
    "\n",
    "\n",
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=16):\n",
    "        super(RelationAttention, self).__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z).mean(0)                    # (M, 1)\n",
    "        beta = torch.softmax(w, dim=0)                 # (M, 1)\n",
    "        beta = beta.expand((z.shape[0],) + beta.shape) # (N, M, 1)\n",
    "        out = (beta * z).sum(1)                        # (N, D * K)\n",
    "        return out\n",
    "    \n",
    "def node_drop(feats, drop_rate, training):\n",
    "    n = feats.shape[0]\n",
    "    drop_rates = torch.FloatTensor(np.ones(n) * drop_rate)\n",
    "    \n",
    "    if training:\n",
    "        masks = torch.bernoulli(1. - drop_rates).unsqueeze(1)\n",
    "        feats = masks.to(feats.device) * feats / (1. - drop_rate)\n",
    "    else:\n",
    "        feats = feats\n",
    "    return feats\n",
    "\n",
    "\n",
    "class custom_GATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 out_feats,\n",
    "                 num_heads,\n",
    "                 feat_drop=0.1,\n",
    "                 attn_drop=0.,\n",
    "                 negative_slope=0.2,\n",
    "                 edge_drop=0.1,\n",
    "                 residual=False,\n",
    "                 activation=None,\n",
    "                 allow_zero_in_degree=False,\n",
    "                 bias=True):\n",
    "        super(custom_GATConv, self).__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._in_src_feats, self._in_dst_feats = expand_as_pair(in_feats)\n",
    "        self._out_feats = out_feats\n",
    "        self._allow_zero_in_degree = allow_zero_in_degree\n",
    "        if isinstance(in_feats, tuple):\n",
    "            self.fc_src = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_dst = nn.Linear(\n",
    "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_src2 = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_dst2 = nn.Linear(\n",
    "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
    "        else:\n",
    "            self.fc = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc2 = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "        self.attn_l = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_r = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_l2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_r2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.feat_drop = nn.Dropout(feat_drop)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        if residual:\n",
    "            if self._in_dst_feats != out_feats:\n",
    "                self.res_fc = nn.Linear(\n",
    "                    self._in_dst_feats, num_heads * out_feats, bias=False)\n",
    "            else:\n",
    "                self.res_fc = Identity()\n",
    "        else:\n",
    "            self.register_buffer('res_fc', None)\n",
    "        self.reset_parameters()\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.edge_drop = edge_drop\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        if hasattr(self, 'fc'):\n",
    "            nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(self.fc_src.weight, gain=gain)\n",
    "            nn.init.xavier_normal_(self.fc_dst.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_l, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_r, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_l2, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_r2, gain=gain)\n",
    "        nn.init.constant_(self.bias, 0)\n",
    "        if isinstance(self.res_fc, nn.Linear):\n",
    "            nn.init.xavier_normal_(self.res_fc.weight, gain=gain)\n",
    "\n",
    "    def set_allow_zero_in_degree(self, set_value):\n",
    "        self._allow_zero_in_degree = set_value\n",
    "\n",
    "    def forward(self, graph, feat, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            if not self._allow_zero_in_degree:\n",
    "                if (graph.in_degrees() == 0).any():\n",
    "                    raise DGLError('There are 0-in-degree nodes in the graph, '\n",
    "                                   'output for those nodes will be invalid. '\n",
    "                                   'This is harmful for some applications, '\n",
    "                                   'causing silent performance regression. '\n",
    "                                   'Adding self-loop on the input graph by '\n",
    "                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n",
    "                                   'the issue. Setting ``allow_zero_in_degree`` '\n",
    "                                   'to be `True` when constructing this module will '\n",
    "                                   'suppress the check and let the code run.')\n",
    "            \n",
    "            if isinstance(feat, tuple):\n",
    "                do_edge_drop = feat[2]\n",
    "                # print('do_edge_drop: ', do_edge_drop)\n",
    "                h_src = self.feat_drop(feat[0])\n",
    "                h_dst = self.feat_drop(feat[1])\n",
    "                h_src2 = h_src.clone()\n",
    "                h_dst2 = h_dst.clone()\n",
    "                if not hasattr(self, 'fc_src'):\n",
    "                    feat_src = self.fc(h_src).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst = self.fc(h_dst).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_src2 = self.fc2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst2 = self.fc2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
    "                else:\n",
    "                    feat_src = self.fc_src(h_src).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst = self.fc_dst(h_dst).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_src2 = self.fc_src2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst2 = self.fc_dst2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
    "            else:\n",
    "                h_src = h_dst = self.feat_drop(feat)\n",
    "                h_src2 = h_dst2 = h_src.clone() # self.feat_drop(feat)\n",
    "                feat_src = feat_dst = self.fc(h_src).view(\n",
    "                    -1, self._num_heads, self._out_feats)\n",
    "                feat_src2 = feat_dst2 = self.fc(h_src).view(\n",
    "                    -1, self._num_heads, self._out_feats)\n",
    "                if graph.is_block:\n",
    "                    feat_dst = feat_src[:graph.number_of_dst_nodes()]\n",
    "                    feat_dst2 = feat_src2[:graph.number_of_dst_nodes()]\n",
    "\n",
    "            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n",
    "            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            graph.srcdata.update({'ft': feat_src, 'el': el, 'feat_src2': feat_src2})\n",
    "            graph.dstdata.update({'er': er, 'feat_dst2': feat_dst2})\n",
    "            # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n",
    "            graph.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
    "            e = self.leaky_relu(graph.edata.pop('e'))\n",
    "            \n",
    "            # compute softmax, edge dropout\n",
    "            if self.training and do_edge_drop and self.edge_drop > 0:\n",
    "                perm = torch.randperm(graph.number_of_edges(), device=e.device)\n",
    "                bound = int(graph.number_of_edges() * self.edge_drop)\n",
    "                eids = perm[bound:]\n",
    "                graph.edata[\"a\"] = torch.zeros_like(e)\n",
    "                graph.edata[\"a\"][eids] = self.attn_drop(edge_softmax(graph, e[eids], eids=eids))\n",
    "            else:\n",
    "                graph.edata['a'] = self.attn_drop(edge_softmax(graph, e))\n",
    "\n",
    "            # message passing\n",
    "            graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n",
    "                             fn.sum('m', 'initial_ft'))\n",
    "            graph.update_all(fn.u_mul_v('feat_src2', 'feat_dst2', 'm2'),\n",
    "                             fn.sum('m2', 'add_ft'))\n",
    "            rst = graph.dstdata['initial_ft'] + graph.dstdata['add_ft']\n",
    "            \n",
    "            # residual\n",
    "            if self.res_fc is not None:\n",
    "                resval = self.res_fc(h_dst).view(h_dst.shape[0], self._num_heads, self._out_feats)\n",
    "                rst = rst + resval\n",
    "            # bias\n",
    "            if self.bias is not None:\n",
    "                rst = rst + self.bias.view(1, self._num_heads, self._out_feats)\n",
    "            # activation\n",
    "            if self.activation:\n",
    "                rst = self.activation(rst)\n",
    "\n",
    "            if get_attention:\n",
    "                return rst, graph.edata['a']\n",
    "            else:\n",
    "                return rst\n",
    "\n",
    "    \n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = 4 # 8\n",
    "        self.hid_feats = int(hid_feats/self.num_heads)\n",
    "        self.out_feats = int(out_feats/self.num_heads)\n",
    "        self.relation_attention = RelationAttention(hid_feats)\n",
    "        \n",
    "        self.gatconv1 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
    "            'i-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'i-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'u-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-u': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            }, aggregate='stack')\n",
    "        \n",
    "        self.gatconv2 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
    "            'i-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'i-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'u-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-u': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            }, aggregate='stack')\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, blocks, inputs, do_edge_drop):\n",
    "        edge_weight_0 = blocks[0].edata['weight']\n",
    "        edge_weight_1 = blocks[1].edata['weight']\n",
    "        \n",
    "        num_users = blocks[-1].dstdata[dgl.NID]['user'].shape[0]\n",
    "        num_recipes = blocks[-1].dstdata[dgl.NID]['recipe'].shape[0]\n",
    "    \n",
    "        h = self.gatconv1(blocks[0], inputs, edge_weight_0, do_edge_drop)\n",
    "        h = {k: F.relu(v).flatten(2) for k, v in h.items()}\n",
    "        h = {k: self.relation_attention(v) for k, v in h.items()} \n",
    "\n",
    "        first_layer_output = {}\n",
    "        first_layer_output['user'] = h['user'][:num_users]\n",
    "        first_layer_output['recipe'] = h['recipe'][:num_recipes]\n",
    "        \n",
    "        h = {key: self.dropout(value) for key, value in h.items()}\n",
    "        h = self.gatconv2(blocks[-1], h, edge_weight_1, do_edge_drop)\n",
    "        last_ingre_and_instr = h['recipe'].flatten(2)\n",
    "        h = {k: self.relation_attention(v.flatten(2)) for k, v in h.items()}\n",
    "\n",
    "        return h\n",
    "    \n",
    "#         # combine several layer embs as the final emb\n",
    "#         combined_output = {}\n",
    "#         combined_output['user'] = torch.cat([h['user'], first_layer_output['user']], dim=1)\n",
    "#         combined_output['recipe'] = torch.cat([h['recipe'], first_layer_output['recipe']], dim=1)\n",
    "#         combined_output['user'] = torch.add(h['user'], first_layer_output['user'])\n",
    "#         combined_output['recipe'] = torch.add(h['recipe'], first_layer_output['recipe'])\n",
    "#         return combined_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(input, p=1, dim=1, eps=1e-12):\n",
    "    return input / input.norm(p, dim, keepdim=True).clamp(min=eps).expand_as(input)\n",
    "\n",
    "def get_recommendation_loss(pos_score, neg_score):\n",
    "    n = pos_score.shape[0]\n",
    "    return (neg_score.view(n, -1) - pos_score.view(n, -1) + 1).clamp(min=0).mean()\n",
    "\n",
    "def get_contrastive_loss(x1, x2):\n",
    "    temperature = 0.07\n",
    "    \n",
    "    # users\n",
    "    x1_user, x2_user = F.normalize(x1['user']), F.normalize(x2['user'])\n",
    "    pos_score_user = torch.mul(x1_user, x2_user).sum(dim=1)\n",
    "    pos_score_user = torch.exp(pos_score_user/temperature)\n",
    "\n",
    "    x2_user_neg = torch.flipud(x2_user)\n",
    "    ttl_score_user = torch.mul(x1_user, x2_user_neg).sum(dim=1)\n",
    "    ttl_score_user = pos_score_user + torch.exp(ttl_score_user/temperature)\n",
    "    \n",
    "    contrastive_loss_user = - torch.log(pos_score_user/ttl_score_user).mean()\n",
    "    # print('contrastive_loss_user: ', contrastive_loss_user)\n",
    "    assert not math.isnan(contrastive_loss_user)\n",
    "\n",
    "    \n",
    "    # recipes\n",
    "    x1_recipe, x2_recipe = F.normalize(x1['recipe']), F.normalize(x2['recipe'])\n",
    "    pos_score_recipe = torch.mul(x1_recipe, x2_recipe).sum(dim=1)\n",
    "    pos_score_recipe = torch.exp(pos_score_recipe/temperature)\n",
    "\n",
    "    x2_recipe_neg = torch.flipud(x2_recipe)\n",
    "    ttl_score_recipe = torch.mul(x1_recipe, x2_recipe_neg).sum(dim=1)\n",
    "    ttl_score_recipe = pos_score_recipe + torch.exp(ttl_score_recipe/temperature) #.sum(dim=1)\n",
    "    \n",
    "    contrastive_loss_recipe = - torch.log(pos_score_recipe/ttl_score_recipe).mean()\n",
    "    # print('contrastive_loss_recipe: ', contrastive_loss_recipe)\n",
    "    \n",
    "    return contrastive_loss_user + contrastive_loss_recipe\n",
    "    \n",
    "def get_emb_loss(*params):\n",
    "    out = None\n",
    "    for param in params:\n",
    "        for k,v in param.items():\n",
    "            if out == None:\n",
    "                out = (v**2/2).mean()\n",
    "            else:\n",
    "                out += (v**2/2).mean()\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Sequential(\n",
    "            nn.Linear(300, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.instr_embedding = nn.Sequential(\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.ingredient_embedding = nn.Sequential(\n",
    "            nn.Linear(46, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.recipe_combine2out = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.gnn = GNN(128, 128, 128, graph.etypes)\n",
    "        self.pred = ScorePredictor()\n",
    "        self.setTransformer_ = SetTransformer()\n",
    "\n",
    "    def forward(self, positive_graph, negative_graph, blocks, input_features):\n",
    "        user, instr, ingredient, ingredient_of_dst_recipe = input_features\n",
    "        \n",
    "        # major GNN\n",
    "        user_major = self.user_embedding(user)\n",
    "        user_major = norm(user_major)\n",
    "        instr_major = self.instr_embedding(instr)\n",
    "        instr_major = norm(instr_major)\n",
    "        ingredient_major = self.ingredient_embedding(ingredient)\n",
    "        ingredient_major = norm(ingredient_major)\n",
    "        x = self.gnn(blocks, {'user': user_major, 'recipe': instr_major, 'ingredient': ingredient_major}, torch.Tensor([[0]]))\n",
    "        \n",
    "        # contrastive - 1\n",
    "        user1 = node_drop(user, 0.1, model.training)\n",
    "        instr1 = node_drop(instr, 0.1, model.training)\n",
    "        ingredient1 = node_drop(ingredient, 0.1, model.training)\n",
    "\n",
    "        user1 = self.user_embedding(user1)\n",
    "        user1 = norm(user1)\n",
    "        instr1 = self.instr_embedding(instr1)\n",
    "        instr1 = norm(instr1)\n",
    "        ingredient1 = self.ingredient_embedding(ingredient1)\n",
    "        ingredient1 = norm(ingredient1)\n",
    "        \n",
    "        x1 = self.gnn(blocks, {'user': user1, 'recipe': instr1, 'ingredient': ingredient1}, torch.Tensor([[1]]))\n",
    "        \n",
    "        # contrastive - 2\n",
    "        user2 = node_drop(user, 0.1, model.training)\n",
    "        instr2 = node_drop(instr, 0.1, model.training)\n",
    "        ingredient2 = node_drop(ingredient, 0.1, model.training)\n",
    "        \n",
    "        user2 = self.user_embedding(user2)\n",
    "        user2 = norm(user2)\n",
    "        instr2 = self.instr_embedding(instr2)\n",
    "        instr2 = norm(instr2)\n",
    "        ingredient2 = self.ingredient_embedding(ingredient2)\n",
    "        ingredient2 = norm(ingredient2)\n",
    "        \n",
    "        x2 = self.gnn(blocks, {'user': user2, 'recipe': instr2, 'ingredient': ingredient2}, torch.Tensor([[1]]))\n",
    "        \n",
    "        # setTransformer\n",
    "        all_ingre_emb_for_each_recipe = get_ingredient_neighbors_all_embeddings(blocks, blocks[1].dstdata['_ID']['recipe'], ingredient_of_dst_recipe)\n",
    "        all_ingre_emb_for_each_recipe = norm(all_ingre_emb_for_each_recipe)\n",
    "        total_ingre_emb = self.setTransformer_(all_ingre_emb_for_each_recipe) # 1\n",
    "        total_ingre_emb = norm(total_ingre_emb)\n",
    "        \n",
    "        # scores\n",
    "        x['recipe'] = self.recipe_combine2out(total_ingre_emb.add(x['recipe']))\n",
    "        pos_score = self.pred(positive_graph, x)\n",
    "        neg_score = self.pred(negative_graph, x)        \n",
    "\n",
    "        return pos_score, neg_score, x1, x2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    # Relevance is binary (nonzero is relevant).\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k]\n",
    "    return np.mean(r)\n",
    "\n",
    "def recall_at_k(r, k, all_pos_num):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum(r) / all_pos_num\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    # method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    #         If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def average_precision_at_k(r, Ks):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = []\n",
    "    for k in Ks:\n",
    "        assert k <= len(r)\n",
    "        # print('[precision_at_k(r, i + 1) for i in range(k) if r[i]]: ', [precision_at_k(r, i + 1) for i in range(k) if r[i]])\n",
    "        all_precision_before_k = [precision_at_k(r, i + 1) for i in range(k) if r[i]]\n",
    "        if len(all_precision_before_k) == 0:\n",
    "            all_precision_before_k = [0]\n",
    "        out.append(np.mean(all_precision_before_k))\n",
    "    if not out:\n",
    "        return 0.\n",
    "    # return np.array([np.mean(out)])\n",
    "    return np.array(out)\n",
    "\n",
    "def get_map_at_k(rs, Ks):\n",
    "    # examples:\n",
    "    # average_precision_at_k([1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [5,10])\n",
    "    # average_precision_at_k([0, 0, 1, 0, 0, 0, 0, 0, 0, 1], [5,10])\n",
    "    # get_map_at_k([[1, 1, 0, 1, 0, 1, 0, 0, 0, 1,1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1,1]], [5,10])\n",
    "    out = np.zeros(len(Ks))\n",
    "    for r in rs:\n",
    "        # print('average_precision_at_k: ', average_precision_at_k(r, Ks))\n",
    "        out += average_precision_at_k(r, Ks)/len(rs)\n",
    "    return out\n",
    "    # return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "def get_ranklist_for_one_user(user_poss, user_negs, Ks):\n",
    "    item_scores = {}\n",
    "    n_pos = len(user_poss)\n",
    "    n_neg = len(user_negs)\n",
    "    for i in range(n_pos):\n",
    "        item_scores[i] = user_poss[i]\n",
    "    for i in range(n_neg):\n",
    "        item_scores[i+1] = user_negs[i]\n",
    "        \n",
    "    K_max = max(Ks)\n",
    "    K_max_item_score = heapq.nlargest(K_max, item_scores, key=item_scores.get)\n",
    "    \n",
    "    r = []\n",
    "    for i in K_max_item_score:\n",
    "        if i < n_pos:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    return r\n",
    "\n",
    "def hit_at_k(r, k):\n",
    "    r = np.array(r)[:k]\n",
    "    if np.sum(r) > 0:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def get_mrr(rs):\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "\n",
    "\n",
    "def get_performance_one_user(user_poss, user_negs, Ks):\n",
    "    r = get_ranklist_for_one_user(user_poss, user_negs, Ks)\n",
    "    \n",
    "    precision, recall, ndcg, hit_ratio = [], [], [], []\n",
    "    for K in Ks:\n",
    "        precision.append(precision_at_k(r, K))\n",
    "        # recall.append(recall_at_k(r, K, len(user_poss))) \n",
    "        ndcg.append(ndcg_at_k(r, K))\n",
    "        hit_ratio.append(hit_at_k(r, K))\n",
    "    # return {'precision': np.array(precision), 'recall': np.array(recall),\n",
    "    #         'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r    \n",
    "    return {'precision': np.array(precision), \n",
    "            'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r\n",
    "\n",
    "\n",
    "def get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks):\n",
    "    # all_result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "    #           'hit_ratio': np.zeros(len(Ks))}\n",
    "    all_result = {'hit_ratio': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)), 'precision': np.zeros(len(Ks))}\n",
    "    \n",
    "    rs = []\n",
    "    n_test_users = len(user2pos_score_dict)\n",
    "    \n",
    "    # one specific user\n",
    "    for user in user2pos_score_dict.keys():\n",
    "        user_pos_score = user2pos_score_dict[user]\n",
    "        user_neg_score = user2neg_score_dict[user]\n",
    "        one_result, one_r = get_performance_one_user(user_pos_score, user_neg_score, Ks)\n",
    "        # all_result['recall'] += one_result['recall']/n_test_users\n",
    "        all_result['hit_ratio'] += one_result['hit_ratio']/n_test_users\n",
    "        all_result['ndcg'] += one_result['ndcg']/n_test_users\n",
    "        all_result['precision'] += one_result['precision']/n_test_users\n",
    "        rs.append(one_r)\n",
    "        \n",
    "    # get MRR\n",
    "    # MRR = get_mrr(rs)\n",
    "    # all_result['MRR'] = MRR\n",
    "    \n",
    "    # get MAP\n",
    "    MAP = get_map_at_k(rs, Ks)\n",
    "    all_result['MAP'] = MAP\n",
    "\n",
    "    return all_result\n",
    "    \n",
    "    \n",
    "def evaluate(model, dataloader, multi_metrics=False):\n",
    "    # print('start evaluating ...')\n",
    "    evaluate_start = time.time()\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    epoch_contrastive_loss = 0\n",
    "    iteration_cnt = 0\n",
    "    total_pos_score = torch.tensor([]).to(device)\n",
    "    total_neg_score = torch.tensor([]).to(device)\n",
    "    \n",
    "    # for evaluation\n",
    "    user2pos_score_dict = {}\n",
    "    user2neg_score_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "            blocks = [b.to(device) for b in blocks]\n",
    "            positive_graph = positive_graph.to(device)\n",
    "            negative_graph = negative_graph.to(device)\n",
    "\n",
    "            input_user = blocks[0].srcdata['random_feature']['user']\n",
    "            input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
    "            input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
    "            ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
    "            input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
    "\n",
    "            pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
    "            contrastive_loss = get_contrastive_loss(x1, x2)\n",
    "            total_pos_score = torch.cat([total_pos_score, pos_score])\n",
    "            total_neg_score = torch.cat([total_neg_score, neg_score])\n",
    "\n",
    "            recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
    "            loss = recommendation_loss # + 0.01 * contrastive_loss      \n",
    "            total_loss += recommendation_loss.item()\n",
    "            epoch_contrastive_loss += contrastive_loss.item()\n",
    "            iteration_cnt += 1\n",
    "            \n",
    "            # for evaluation\n",
    "            global_test_users = blocks[1].dstdata['_ID']['user'] # we need to map the user id in subgraph to the whole graph\n",
    "            test_users, test_recipes = positive_graph.edges(etype='u-r')\n",
    "            test_users = test_users.tolist()\n",
    "            test_recipes = test_recipes.tolist()\n",
    "            for index in range(len(test_users)):\n",
    "                test_u = int(global_test_users[test_users[index]])\n",
    "                test_r = int(test_recipes[index])\n",
    "                test_score = float(pos_score[index])\n",
    "                \n",
    "                if test_u not in user2pos_score_dict:\n",
    "                    user2pos_score_dict[test_u] = []\n",
    "                user2pos_score_dict[test_u].append(test_score)\n",
    "                \n",
    "                if test_u not in user2neg_score_dict:\n",
    "                    user2neg_score_dict[test_u] = neg_score[index*n_test_negs:(index+1)*n_test_negs]\n",
    "                \n",
    "            # break\n",
    "            \n",
    "        total_loss /= iteration_cnt\n",
    "        epoch_contrastive_loss /= iteration_cnt\n",
    "        \n",
    "        # metrics\n",
    "        auc = compute_auc(total_pos_score, total_neg_score)\n",
    "        if multi_metrics:\n",
    "            # evaluation_result = get_performance_all_users(total_pos_score, total_neg_score, Ks)\n",
    "            evaluation_result = get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks)\n",
    "            evaluation_result['AUC'] = auc\n",
    "            print('evaluation_result: ', evaluation_result)\n",
    "            print('epoch_contrastive_loss: ', epoch_contrastive_loss)\n",
    "        else:\n",
    "            print('AUC: ', auc)\n",
    "        \n",
    "        evalutate_time = time.strftime(\"%M:%S min\", time.gmtime(time.time()-evaluate_start))\n",
    "        print('evalutate_time: ', evalutate_time)\n",
    "    return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ... \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m input_nodes, positive_graph, negative_graph, blocks \u001b[39min\u001b[39;00m train_edgeloader:\n\u001b[1;32m     14\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 15\u001b[0m     blocks \u001b[39m=\u001b[39m [b\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m blocks]\n\u001b[1;32m     16\u001b[0m     positive_graph \u001b[39m=\u001b[39m positive_graph\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     negative_graph \u001b[39m=\u001b[39m negative_graph\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m input_nodes, positive_graph, negative_graph, blocks \u001b[39min\u001b[39;00m train_edgeloader:\n\u001b[1;32m     14\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 15\u001b[0m     blocks \u001b[39m=\u001b[39m [b\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m blocks]\n\u001b[1;32m     16\u001b[0m     positive_graph \u001b[39m=\u001b[39m positive_graph\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     negative_graph \u001b[39m=\u001b[39m negative_graph\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.8/site-packages/dgl/heterograph.py:5709\u001b[0m, in \u001b[0;36mDGLGraph.to\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5706\u001b[0m ret \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m   5708\u001b[0m \u001b[39m# 1. Copy graph structure\u001b[39;00m\n\u001b[0;32m-> 5709\u001b[0m ret\u001b[39m.\u001b[39m_graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mcopy_to(utils\u001b[39m.\u001b[39;49mto_dgl_context(device))\n\u001b[1;32m   5711\u001b[0m \u001b[39m# 2. Copy features\u001b[39;00m\n\u001b[1;32m   5712\u001b[0m \u001b[39m# TODO(minjie): handle initializer\u001b[39;00m\n\u001b[1;32m   5713\u001b[0m new_nframes \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/tesi/lib/python3.8/site-packages/dgl/utils/internal.py:585\u001b[0m, in \u001b[0;36mto_dgl_context\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_dgl_context\u001b[39m(ctx):\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\"\"Convert a backend context to DGLContext\"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     device_type \u001b[39m=\u001b[39m nd\u001b[39m.\u001b[39;49mDGLContext\u001b[39m.\u001b[39;49mSTR2MASK[F\u001b[39m.\u001b[39;49mdevice_type(ctx)]\n\u001b[1;32m    586\u001b[0m     device_id \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdevice_id(ctx)\n\u001b[1;32m    587\u001b[0m     \u001b[39mreturn\u001b[39;00m nd\u001b[39m.\u001b[39mDGLContext(device_type, device_id)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mps'"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.9)\n",
    "\n",
    "print('start ... ')\n",
    "for epoch in range(50):\n",
    "    train_start = time.time()\n",
    "    epoch_loss = 0\n",
    "    epoch_contrastive_loss = 0\n",
    "    epoch_emb_loss = 0\n",
    "    iteration_cnt = 0\n",
    "    \n",
    "    for input_nodes, positive_graph, negative_graph, blocks in train_edgeloader:\n",
    "        model.train()\n",
    "        blocks = [b.to(device) for b in blocks]\n",
    "        positive_graph = positive_graph.to(device)\n",
    "        negative_graph = negative_graph.to(device)\n",
    "        \n",
    "        input_user = blocks[0].srcdata['random_feature']['user']\n",
    "        input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
    "        input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
    "        ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
    "        input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
    "        \n",
    "        pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
    "        contrastive_loss = get_contrastive_loss(x1, x2)\n",
    "        # emb_loss = get_emb_loss(x1, x2)\n",
    "        assert not math.isnan(contrastive_loss)        \n",
    "        recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
    "        assert not math.isnan(recommendation_loss)\n",
    "        \n",
    "        loss = recommendation_loss + 0.1 * contrastive_loss # + 1e-5 * emb_loss\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        epoch_loss += recommendation_loss.item()\n",
    "        epoch_contrastive_loss += contrastive_loss.item()\n",
    "        # epoch_emb_loss += emb_loss.item()\n",
    "        iteration_cnt += 1\n",
    "\n",
    "        # break\n",
    "        \n",
    "    epoch_loss /= iteration_cnt\n",
    "    epoch_contrastive_loss /= iteration_cnt\n",
    "    train_end = time.strftime(\"%M:%S min\", time.gmtime(time.time()-train_start))\n",
    "    \n",
    "    print('Epoch: {0},  Loss: {l:.4f}, Contrastive: {cl:.4f}, Emb: {el:.4f},  Time: {t}, LR: {lr:.6f}'\n",
    "          .format(epoch, l=epoch_loss, cl=epoch_contrastive_loss, el=epoch_emb_loss, t=train_end, lr=opt.param_groups[0]['lr']))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    # For demonstration purpose, only test set result is reported here. Please use val_dataloader for comprehensiveness.\n",
    "    if epoch >= 4 and epoch % 1 == 0:\n",
    "        print('testing: ')\n",
    "        evaluate(model, test_edgeloader, multi_metrics=True)\n",
    "        print()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
