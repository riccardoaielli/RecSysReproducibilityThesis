{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 16 15:07:07 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   22C    P8     9W / 250W |      2MiB / 12196MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   23C    P8     8W / 250W |      2MiB / 12196MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN X (Pascal)    Off  | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 23%   19C    P8     9W / 250W |      2MiB / 12196MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN X (Pascal)    Off  | 00000000:83:00.0 Off |                  N/A |\r\n",
      "| 23%   24C    P8     9W / 250W |      2MiB / 12196MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "# import lmdb\n",
    "import gensim\n",
    "import heapq\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import torchfile\n",
    "from torch.nn import init\n",
    "import dgl.function as fn\n",
    "from dgl.utils import expand_as_pair\n",
    "# from dgl.nn import EdgeWeightNorm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "Ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # top@K performance\n",
    "n_test_negs = 100 # number of negative recipes for each test user\n",
    "dataset_folder = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph ...\n",
      "graph:  Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 135353, ('user', 'u-r', 'recipe'): 135353},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
     ]
    }
   ],
   "source": [
    "def get_graph():\n",
    "    print('generating graph ...')\n",
    "    edge_src, edge_dst, r_i_edge_weight = torch.load(dataset_folder+'/edge_r2i_src_dst_weight.pt')\n",
    "    recipe_edge_src, recipe_edge_dst, recipe_edge_weight = torch.load(dataset_folder+'/edge_r2r_src_and_dst_and_weight.pt')\n",
    "    ingre_edge_src, ingre_edge_dst, ingre_edge_weight = torch.load(dataset_folder+'/edge_i2i_src_and_dst_and_weight.pt')\n",
    "    all_u2r_src_dst_weight, train_u2r_src_dst_weight, val_u2r_src_dst_weight, test_u2r_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
    "    u_rate_r_edge_src, u_rate_r_edge_dst, u_rate_r_edge_weight = all_u2r_src_dst_weight\n",
    "    \n",
    "    # nodes and edges\n",
    "    graph = dgl.heterograph({\n",
    "        ('recipe', 'r-i', 'ingredient'): (edge_src, edge_dst),\n",
    "        ('ingredient', 'i-r', 'recipe'): (edge_dst, edge_src),\n",
    "        ('recipe', 'r-r', 'recipe'): (recipe_edge_src, recipe_edge_dst),\n",
    "        ('ingredient', 'i-i', 'ingredient'): (ingre_edge_src, ingre_edge_dst),\n",
    "        ('user', 'u-r', 'recipe'): (u_rate_r_edge_src, u_rate_r_edge_dst),\n",
    "        ('recipe', 'r-u', 'user'): (u_rate_r_edge_dst, u_rate_r_edge_src)\n",
    "    })\n",
    "\n",
    "    # edge weight\n",
    "    graph.edges['r-i'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
    "    graph.edges['i-r'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
    "    graph.edges['r-r'].data['weight'] = torch.FloatTensor(recipe_edge_weight)\n",
    "    graph.edges['i-i'].data['weight'] = torch.FloatTensor(ingre_edge_weight)\n",
    "    graph.edges['u-r'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
    "    graph.edges['r-u'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
    "    \n",
    "    # node features\n",
    "    recipe_nodes_avg_instruction_features = torch.load(dataset_folder+'/recipe_nodes_avg_instruction_features.pt')\n",
    "    ingredient_nodes_nutrient_features_minus1 = torch.load(dataset_folder+'/ingredient_nodes_nutrient_features.pt')\n",
    "    graph.nodes['recipe'].data['avg_instr_feature'] = recipe_nodes_avg_instruction_features\n",
    "    graph.nodes['ingredient'].data['nutrient_feature'] = ingredient_nodes_nutrient_features_minus1\n",
    "    graph.nodes['user'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(7959, 300))\n",
    "    graph.nodes['recipe'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(68794, 1024))\n",
    "\n",
    "    return graph\n",
    "\n",
    "graph = get_graph()\n",
    "print('graph: ', graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all_src:  135353\n",
      "length of train_eids:  119435\n",
      "length of val_eids:  7959\n",
      "length of test_eids:  7959\n"
     ]
    }
   ],
   "source": [
    "all_src_dst_weight, train_src_dst_weight, val_src_dst_weight, test_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
    "all_src, all_dst, all_weight = all_src_dst_weight\n",
    "train_src, train_dst, train_weight = train_src_dst_weight\n",
    "val_src, val_dst, val_weight = val_src_dst_weight\n",
    "test_src, test_dst, test_weight = test_src_dst_weight\n",
    "\n",
    "train_eids = graph.edge_ids(train_src, train_dst, etype='u-r')\n",
    "val_eids = graph.edge_ids(val_src, val_dst, etype='u-r')\n",
    "test_eids = graph.edge_ids(test_src, test_dst, etype='u-r')\n",
    "val_eids_r2u = graph.edge_ids(val_dst, val_src, etype='r-u')\n",
    "test_eids_r2u = graph.edge_ids(test_dst, test_src, etype='r-u')\n",
    "print('length of all_src: ', len(all_src))\n",
    "print('length of train_eids: ', len(train_eids))\n",
    "print('length of val_eids: ', len(val_eids))\n",
    "print('length of test_eids: ', len(test_eids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training graph: \n",
      "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 119435, ('user', 'u-r', 'recipe'): 119435},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n",
      "\n",
      "val graph: \n",
      "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 127394, ('user', 'u-r', 'recipe'): 127394},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
     ]
    }
   ],
   "source": [
    "# get train_graph and val_graph\n",
    "train_graph = graph.clone()\n",
    "train_graph.remove_edges(torch.cat([val_eids, test_eids]), etype='u-r')\n",
    "train_graph.remove_edges(torch.cat([val_eids_r2u, test_eids_r2u]), etype='r-u')\n",
    "print('training graph: ')\n",
    "print(train_graph)\n",
    "print()\n",
    "\n",
    "val_graph = graph.clone()\n",
    "val_graph.remove_edges(test_eids, etype='u-r')\n",
    "val_graph.remove_edges(test_eids, etype='r-u')\n",
    "print('val graph: ')\n",
    "print(val_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7959/7959 [00:00<00:00, 34527.43it/s]\n",
      "100%|██████████| 7959/7959 [00:00<00:00, 33962.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of batches in train_edgeloader:  117\n",
      "# of batches in val_edgeloader:  63\n",
      "# of batches in test_edgeloader:  63\n",
      "\n",
      "blocks:  [Block(num_src_nodes={'ingredient': 6521, 'recipe': 61844, 'user': 5862},\n",
      "      num_dst_nodes={'ingredient': 3800, 'recipe': 27121, 'user': 3024},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 48580, ('ingredient', 'i-r', 'recipe'): 177370, ('recipe', 'r-i', 'ingredient'): 51767, ('recipe', 'r-r', 'recipe'): 254241, ('recipe', 'r-u', 'user'): 35130, ('user', 'u-r', 'recipe'): 52385},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')]), Block(num_src_nodes={'ingredient': 3800, 'recipe': 27121, 'user': 3024},\n",
      "      num_dst_nodes={'ingredient': 0, 'recipe': 5881, 'user': 666},\n",
      "      num_edges={('ingredient', 'i-i', 'ingredient'): 0, ('ingredient', 'i-r', 'recipe'): 39727, ('recipe', 'r-i', 'ingredient'): 0, ('recipe', 'r-r', 'recipe'): 31697, ('recipe', 'r-u', 'user'): 10113, ('user', 'u-r', 'recipe'): 9851},\n",
      "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])]\n"
     ]
    }
   ],
   "source": [
    "# edge dataloaders\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([20, 20])\n",
    "neg_sampler = dgl.dataloading.negative_sampler.Uniform(5)\n",
    "\n",
    "class test_NegativeSampler(object):\n",
    "    def __init__(self, g, k):\n",
    "        # get the negatives\n",
    "        self.user2negs_100_dict = {}\n",
    "        filename = dataset_folder+'/test_negatives_100.txt'\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in tqdm(lines):\n",
    "                if line == None or line == \"\":\n",
    "                    continue\n",
    "                line = line[:-1] # remove \\n\n",
    "                user = int(line.split('\\t')[0].split(',')[0][1:])\n",
    "                negs = [int(neg) for neg in line.split('\\t')[1:]]\n",
    "                self.user2negs_100_dict[user] = negs\n",
    "                \n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, g, eids_dict):\n",
    "        result_dict = {}\n",
    "        for etype, eids in eids_dict.items():\n",
    "            src, _ = g.find_edges(eids, etype=etype)\n",
    "            dst = []\n",
    "            for each_src in src:\n",
    "                dst.extend(self.user2negs_100_dict[int(each_src)][:self.k])\n",
    "            dst = torch.tensor(dst)\n",
    "            src = src.repeat_interleave(self.k)\n",
    "            result_dict[etype] = (src, dst)\n",
    "        return result_dict\n",
    "    \n",
    "test_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
    "test_train_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
    "    \n",
    "train_collator = dgl.dataloading.EdgeCollator(\n",
    "    train_graph, {'u-r': train_graph.edge_ids(train_src, train_dst, etype='u-r')}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=neg_sampler)\n",
    "val_collator = dgl.dataloading.EdgeCollator(\n",
    "    val_graph, {'u-r': val_graph.edge_ids(val_src, val_dst, etype='u-r')}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=neg_sampler)\n",
    "test_collator = dgl.dataloading.EdgeCollator(\n",
    "    graph, {('user', 'u-r', 'recipe'): test_eids}, sampler, \n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
    "    negative_sampler=test_neg_sampler)\n",
    "\n",
    "train_edgeloader = torch.utils.data.DataLoader(\n",
    "    train_collator.dataset, collate_fn=train_collator.collate,\n",
    "    batch_size=1024, shuffle=True, drop_last=False, num_workers=0)\n",
    "val_edgeloader = torch.utils.data.DataLoader(\n",
    "    val_collator.dataset, collate_fn=val_collator.collate,\n",
    "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
    "test_edgeloader = torch.utils.data.DataLoader(\n",
    "    test_collator.dataset, collate_fn=test_collator.collate,\n",
    "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "print('# of batches in train_edgeloader: ', len(train_edgeloader))\n",
    "print('# of batches in val_edgeloader: ', len(val_edgeloader))\n",
    "print('# of batches in test_edgeloader: ', len(test_edgeloader))\n",
    "print()\n",
    "\n",
    "for input_nodes, pos_pair_graph, neg_pair_graph, blocks in train_edgeloader:\n",
    "    print('blocks: ', blocks)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68794/68794 [00:17<00:00, 4012.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingre_neighbor_tensor:  torch.Size([68794, 33])\n",
      "ingre_length_tensor:  torch.Size([68794])\n",
      "total_length_index_list:  68795\n",
      "total_ingre_neighbor_tensor:  torch.Size([454941])\n"
     ]
    }
   ],
   "source": [
    "# get ingre neighbors for each recipe nodes\n",
    "def get_recipe2ingreNeighbor_dict():\n",
    "    max_length = 33\n",
    "    out = {}\n",
    "    neighbor_list = []\n",
    "    ingre_length_list = []\n",
    "    total_length_index_list = []\n",
    "    total_ingre_neighbor_list = []\n",
    "    total_length_index = 0\n",
    "    total_length_index_list.append(total_length_index)\n",
    "    for recipeNodeID in tqdm(range(graph.number_of_nodes('recipe'))):\n",
    "        _, succs = graph.out_edges(recipeNodeID, etype='r-i')\n",
    "        succs_list = list(set(succs.tolist()))\n",
    "        total_ingre_neighbor_list.extend(succs_list)\n",
    "        cur_length = len(succs_list)\n",
    "        ingre_length_list.append(cur_length)\n",
    "        \n",
    "        total_length_index += cur_length\n",
    "        total_length_index_list.append(total_length_index)\n",
    "        while len(succs_list) < max_length:\n",
    "            succs_list.append(77733)\n",
    "        neighbor_list.append(succs_list)\n",
    "\n",
    "    ingre_neighbor_tensor = torch.tensor(neighbor_list)\n",
    "    ingre_length_tensor = torch.tensor(ingre_length_list)\n",
    "    total_ingre_neighbor_tensor = torch.tensor(total_ingre_neighbor_list)\n",
    "    return ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor\n",
    "\n",
    "ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor = get_recipe2ingreNeighbor_dict()\n",
    "print('ingre_neighbor_tensor: ', ingre_neighbor_tensor.shape)\n",
    "print('ingre_length_tensor: ', ingre_length_tensor.shape)\n",
    "print('total_length_index_list: ', len(total_length_index_list))\n",
    "print('total_ingre_neighbor_tensor: ', total_ingre_neighbor_tensor.shape)\n",
    "\n",
    "def find(tensor, values):\n",
    "    return torch.nonzero(tensor[..., None] == values)\n",
    "\n",
    "# example of find()\n",
    "# a = torch.tensor([0, 10, 20, 30])\n",
    "# b = torch.tensor([[ 0, 30, 20,  10, 77733],[ 0, 30, 20,  10, 77733]])\n",
    "# find(b, a)[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient_neighbors_all_embeddings(blocks, output_nodes, secondToLast_ingre):\n",
    "    ingreNodeIDs = blocks[1].srcdata['_ID']['ingredient']\n",
    "    recipeNodeIDs = output_nodes\n",
    "    batch_ingre_neighbors = ingre_neighbor_tensor[recipeNodeIDs].to(device)\n",
    "    batch_ingre_length = ingre_length_tensor[recipeNodeIDs]\n",
    "    valid_batch_ingre_neighbors = find(batch_ingre_neighbors, ingreNodeIDs)[:, 2]\n",
    "    \n",
    "    # based on valid_batch_ingre_neighbors each row index\n",
    "    _, valid_batch_ingre_length = torch.unique(find(batch_ingre_neighbors, ingreNodeIDs)[:, 0], return_counts=True)\n",
    "    batch_sum_ingre_length = np.cumsum(valid_batch_ingre_length.cpu())\n",
    "    \n",
    "    total_ingre_emb = None\n",
    "    for i in range(len(recipeNodeIDs)):\n",
    "        if i == 0:\n",
    "            recipeNode_ingres = valid_batch_ingre_neighbors[0:batch_sum_ingre_length[i]]\n",
    "            a = secondToLast_ingre[recipeNode_ingres]\n",
    "        else:\n",
    "            recipeNode_ingres = valid_batch_ingre_neighbors[batch_sum_ingre_length[i-1]:batch_sum_ingre_length[i]]\n",
    "            a = secondToLast_ingre[recipeNode_ingres]\n",
    "    \n",
    "        # all ingre instead of average\n",
    "        a_rows = a.shape[0]\n",
    "        a_columns = a.shape[1]\n",
    "        max_rows = 5\n",
    "        if a_rows < max_rows:\n",
    "            a = torch.cat([a, torch.zeros(max_rows-a_rows, a_columns).cuda()])\n",
    "        else:\n",
    "            a = a[:max_rows, :]\n",
    "        \n",
    "        if total_ingre_emb == None:\n",
    "            total_ingre_emb = a.unsqueeze(0)\n",
    "        else:\n",
    "            total_ingre_emb = torch.cat([total_ingre_emb,a.unsqueeze(0)], dim = 0)\n",
    "            if torch.isnan(total_ingre_emb).any():\n",
    "                print('Error!')\n",
    "\n",
    "    return total_ingre_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Scaled Dot-Product Attention.\"\"\"\n",
    "\n",
    "    def __init__(self, temperature):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"\n",
    "        It is equivariant to permutations\n",
    "        of the batch dimension (`b`).\n",
    "\n",
    "        It is equivariant to permutations of the\n",
    "        second dimension of the queries (`n`).\n",
    "\n",
    "        It is invariant to permutations of the\n",
    "        second dimension of keys and values (`m`).\n",
    "\n",
    "        Arguments:\n",
    "            queries: a float tensor with shape [b, n, d].\n",
    "            keys: a float tensor with shape [b, m, d].\n",
    "            values: a float tensor with shape [b, m, d'].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d'].\n",
    "        \"\"\"\n",
    "\n",
    "        attention = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        attention = self.softmax(attention / self.temperature)\n",
    "        # it has shape [b, n, m]\n",
    "\n",
    "        return torch.bmm(attention, values)\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, dimension of queries and values.\n",
    "                It is assumed that input and\n",
    "                output dimensions are the same.\n",
    "            h: an integer, number of heads.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert d % h == 0\n",
    "        self.h = h\n",
    "\n",
    "        # everything is projected to this dimension\n",
    "        p = d // h\n",
    "\n",
    "        self.project_queries = nn.Linear(d, d)\n",
    "        self.project_keys = nn.Linear(d, d)\n",
    "        self.project_values = nn.Linear(d, d)\n",
    "        self.concatenation = nn.Linear(d, d)\n",
    "        self.attention = Attention(temperature=p**0.5)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            queries: a float tensor with shape [b, n, d].\n",
    "            keys: a float tensor with shape [b, m, d].\n",
    "            values: a float tensor with shape [b, m, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.h\n",
    "        b, n, d = queries.size()\n",
    "        _, m, _ = keys.size()\n",
    "        p = d // h\n",
    "\n",
    "        queries = self.project_queries(queries)  # shape [b, n, d]\n",
    "        keys = self.project_keys(keys)  # shape [b, m, d]\n",
    "        values = self.project_values(values)  # shape [b, m, d]\n",
    "\n",
    "        queries = queries.view(b, n, h, p)\n",
    "        keys = keys.view(b, m, h, p)\n",
    "        values = values.view(b, m, h, p)\n",
    "\n",
    "        queries = queries.permute(2, 0, 1, 3).contiguous().view(h * b, n, p)\n",
    "        keys = keys.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
    "        values = values.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
    "\n",
    "        output = self.attention(queries, keys, values)  # shape [h * b, n, p]\n",
    "        output = output.view(h, b, n, p)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(b, n, d)\n",
    "        output = self.concatenation(output)  # shape [b, n, d]\n",
    "\n",
    "        return output\n",
    "\n",
    "class RFF(nn.Module):\n",
    "    \"\"\"\n",
    "    Row-wise FeedForward layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
    "            nn.Linear(d, d), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiheadAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h, rff):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            h: an integer, number of heads.\n",
    "            rff: a module, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.multihead = MultiheadAttention(d, h)\n",
    "        self.layer_norm1 = nn.LayerNorm(d)\n",
    "        self.layer_norm2 = nn.LayerNorm(d)\n",
    "        self.rff = rff\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        It is equivariant to permutations of the\n",
    "        second dimension of tensor x (`n`).\n",
    "\n",
    "        It is invariant to permutations of the\n",
    "        second dimension of tensor y (`m`).\n",
    "\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "            y: a float tensor with shape [b, m, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        h = self.layer_norm1(x + self.multihead(x, y, y))\n",
    "        return self.layer_norm2(h + self.rff(h))\n",
    "\n",
    "class SetAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, h, rff):\n",
    "        super().__init__()\n",
    "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        return self.mab(x, x)\n",
    "\n",
    "class InducedSetAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d, m, h, rff1, rff2):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            m: an integer, number of inducing points.\n",
    "            h: an integer, number of heads.\n",
    "            rff1, rff2: modules, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mab1 = MultiheadAttentionBlock(d, h, rff1)\n",
    "        self.mab2 = MultiheadAttentionBlock(d, h, rff2)\n",
    "        self.inducing_points = nn.Parameter(torch.randn(1, m, d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, n, d].\n",
    "        \"\"\"\n",
    "        b = x.size(0)\n",
    "        p = self.inducing_points\n",
    "        p = p.repeat([b, 1, 1])  # shape [b, m, d]\n",
    "        h = self.mab1(p, x)  # shape [b, m, d]\n",
    "        return self.mab2(x, h)\n",
    "\n",
    "class PoolingMultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d, k, h, rff):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d: an integer, input dimension.\n",
    "            k: an integer, number of seed vectors.\n",
    "            h: an integer, number of heads.\n",
    "            rff: a module, row-wise feedforward layers.\n",
    "                It takes a float tensor with shape [b, n, d] and\n",
    "                returns a float tensor with the same shape.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
    "        self.seed_vectors = nn.Parameter(torch.randn(1, k, d))\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            z: a float tensor with shape [b, n, d].\n",
    "        Returns:\n",
    "            a float tensor with shape [b, k, d].\n",
    "        \"\"\"\n",
    "        b = z.size(0)\n",
    "        s = self.seed_vectors\n",
    "        s = s.repeat([b, 1, 1])  # random seed vector: shape [b, k, d]\n",
    "\n",
    "        output = self.mab(s, z)\n",
    "        # print('PoolingMultiheadAttention', output.shape)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set transformer for ingredient representation\n",
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            in_dimension: an integer.  # 2\n",
    "            out_dimension: an integer. # 5 * K\n",
    "        \"\"\"\n",
    "        super(SetTransformer, self).__init__()\n",
    "        in_dimension = 46 # 300\n",
    "        out_dimension = 128 # 600\n",
    "\n",
    "        d = in_dimension\n",
    "        m = 46  # number of inducing points\n",
    "        h = 2  # 4 # number of heads\n",
    "        k = 4  # number of seed vectors\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d)),\n",
    "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d))\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            PoolingMultiheadAttention(d, k, h, RFF(d)),\n",
    "            SetAttentionBlock(d, h, RFF(d))\n",
    "        )\n",
    "\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            PoolingMultiheadAttention(d, k, h, RFF(d))\n",
    "        )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            SetAttentionBlock(d, h, RFF(d))\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(k * d, out_dimension),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: a float tensor with shape [batch, n, in_dimension].\n",
    "        Returns:\n",
    "            a float tensor with shape [batch, out_dimension].\n",
    "        \"\"\"\n",
    "        x = self.encoder(x) # x = self.encoder(cut_x) # shape [batch, batch_max_len, d]\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder(x)  # shape [batch, k, d]\n",
    "\n",
    "        b, k, d = x.shape\n",
    "        x = x.view(b, k * d)\n",
    "\n",
    "        y = self.predictor(x)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_HeteroGraphConv(nn.Module):\n",
    "    def __init__(self, mods, aggregate='sum'):\n",
    "        super(custom_HeteroGraphConv, self).__init__()\n",
    "        self.mods = nn.ModuleDict(mods)\n",
    "        # Do not break if graph has 0-in-degree nodes.\n",
    "        # Because there is no general rule to add self-loop for heterograph.\n",
    "        for _, v in self.mods.items():\n",
    "            set_allow_zero_in_degree_fn = getattr(v, 'set_allow_zero_in_degree', None)\n",
    "            if callable(set_allow_zero_in_degree_fn):\n",
    "                set_allow_zero_in_degree_fn(True)\n",
    "        if isinstance(aggregate, str):\n",
    "            self.agg_fn = get_aggregate_fn(aggregate)\n",
    "        else:\n",
    "            self.agg_fn = aggregate\n",
    "\n",
    "    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):\n",
    "        if mod_args is None:\n",
    "            mod_args = {}\n",
    "        if mod_kwargs is None:\n",
    "            mod_kwargs = {}\n",
    "        outputs = {nty : [] for nty in g.dsttypes}\n",
    "        if isinstance(inputs, tuple) or g.is_block:\n",
    "            if isinstance(inputs, tuple):\n",
    "                src_inputs, dst_inputs = inputs\n",
    "            else:\n",
    "                src_inputs = inputs\n",
    "                dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
    "\n",
    "            for stype, etype, dtype in g.canonical_etypes:\n",
    "                rel_graph = g[stype, etype, dtype]\n",
    "                if rel_graph.number_of_edges() == 0:\n",
    "                    continue\n",
    "                if stype not in src_inputs or dtype not in dst_inputs:\n",
    "                    continue\n",
    "                dstdata = self.mods[etype](\n",
    "                    rel_graph,\n",
    "                    (src_inputs[stype], dst_inputs[dtype], mod_kwargs),\n",
    "                    *mod_args.get(etype, ())\n",
    "                    )\n",
    "                outputs[dtype].append(dstdata)\n",
    "        else:\n",
    "            for stype, etype, dtype in g.canonical_etypes:\n",
    "                rel_graph = g[stype, etype, dtype]\n",
    "                if rel_graph.number_of_edges() == 0:\n",
    "                    continue\n",
    "                if stype not in inputs:\n",
    "                    continue\n",
    "                dstdata = self.mods[etype](\n",
    "                    rel_graph,\n",
    "                    (inputs[stype], inputs[dtype], mod_kwargs),\n",
    "                    *mod_args.get(etype, ())\n",
    "                    )\n",
    "                outputs[dtype].append(dstdata)\n",
    "        rsts = {}\n",
    "        for nty, alist in outputs.items():\n",
    "            if len(alist) != 0:\n",
    "                rsts[nty] = self.agg_fn(alist, nty)\n",
    "        return rsts\n",
    "\n",
    "def _max_reduce_func(inputs, dim):\n",
    "    return torch.max(inputs, dim=dim)[0]\n",
    "\n",
    "def _min_reduce_func(inputs, dim):\n",
    "    return torch.min(inputs, dim=dim)[0]\n",
    "\n",
    "def _sum_reduce_func(inputs, dim):\n",
    "    return torch.sum(inputs, dim=dim)\n",
    "\n",
    "def _mean_reduce_func(inputs, dim):\n",
    "    return torch.mean(inputs, dim=dim)\n",
    "\n",
    "def _stack_agg_func(inputs, dsttype):\n",
    "    if len(inputs) == 0:\n",
    "        return None\n",
    "    return torch.stack(inputs, dim=1)\n",
    "\n",
    "def _agg_func(inputs, dsttype, fn):\n",
    "    if len(inputs) == 0:\n",
    "        return None\n",
    "    stacked = torch.stack(inputs, dim=0)\n",
    "    return fn(stacked, dim=0)\n",
    "\n",
    "def get_aggregate_fn(agg):\n",
    "    if agg == 'sum':\n",
    "        fn = _sum_reduce_func\n",
    "    elif agg == 'max':\n",
    "        fn = _max_reduce_func\n",
    "    elif agg == 'min':\n",
    "        fn = _min_reduce_func\n",
    "    elif agg == 'mean':\n",
    "        fn = _mean_reduce_func\n",
    "    elif agg == 'stack':\n",
    "        fn = None  # will not be called\n",
    "    else:\n",
    "        raise DGLError('Invalid cross type aggregator. Must be one of '\n",
    "                       '\"sum\", \"max\", \"min\", \"mean\" or \"stack\". But got \"%s\"' % agg)\n",
    "    if agg == 'stack':\n",
    "        return _stack_agg_func\n",
    "    else:\n",
    "        return partial(_agg_func, fn=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata['x'] = x\n",
    "            edge_subgraph.apply_edges(dgl.function.u_dot_v('x', 'x', 'score'), etype='u-r')\n",
    "            return edge_subgraph.edata['score'][('user', 'u-r', 'recipe')].squeeze()\n",
    "\n",
    "\n",
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=16):\n",
    "        super(RelationAttention, self).__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z).mean(0)                    # (M, 1)\n",
    "        beta = torch.softmax(w, dim=0)                 # (M, 1)\n",
    "        beta = beta.expand((z.shape[0],) + beta.shape) # (N, M, 1)\n",
    "        out = (beta * z).sum(1)                        # (N, D * K)\n",
    "        return out\n",
    "    \n",
    "def node_drop(feats, drop_rate, training):\n",
    "    n = feats.shape[0]\n",
    "    drop_rates = torch.FloatTensor(np.ones(n) * drop_rate)\n",
    "    \n",
    "    if training:\n",
    "        masks = torch.bernoulli(1. - drop_rates).unsqueeze(1)\n",
    "        feats = masks.to(feats.device) * feats / (1. - drop_rate)\n",
    "    else:\n",
    "        feats = feats\n",
    "    return feats\n",
    "\n",
    "\n",
    "class custom_GATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 out_feats,\n",
    "                 num_heads,\n",
    "                 feat_drop=0.1,\n",
    "                 attn_drop=0.,\n",
    "                 negative_slope=0.2,\n",
    "                 edge_drop=0.1,\n",
    "                 residual=False,\n",
    "                 activation=None,\n",
    "                 allow_zero_in_degree=False,\n",
    "                 bias=True):\n",
    "        super(custom_GATConv, self).__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._in_src_feats, self._in_dst_feats = expand_as_pair(in_feats)\n",
    "        self._out_feats = out_feats\n",
    "        self._allow_zero_in_degree = allow_zero_in_degree\n",
    "        if isinstance(in_feats, tuple):\n",
    "            self.fc_src = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_dst = nn.Linear(\n",
    "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_src2 = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc_dst2 = nn.Linear(\n",
    "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
    "        else:\n",
    "            self.fc = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "            self.fc2 = nn.Linear(\n",
    "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
    "        self.attn_l = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_r = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_l2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.attn_r2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
    "        self.feat_drop = nn.Dropout(feat_drop)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        if residual:\n",
    "            if self._in_dst_feats != out_feats:\n",
    "                self.res_fc = nn.Linear(\n",
    "                    self._in_dst_feats, num_heads * out_feats, bias=False)\n",
    "            else:\n",
    "                self.res_fc = Identity()\n",
    "        else:\n",
    "            self.register_buffer('res_fc', None)\n",
    "        self.reset_parameters()\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.edge_drop = edge_drop\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        if hasattr(self, 'fc'):\n",
    "            nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(self.fc_src.weight, gain=gain)\n",
    "            nn.init.xavier_normal_(self.fc_dst.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_l, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_r, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_l2, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_r2, gain=gain)\n",
    "        nn.init.constant_(self.bias, 0)\n",
    "        if isinstance(self.res_fc, nn.Linear):\n",
    "            nn.init.xavier_normal_(self.res_fc.weight, gain=gain)\n",
    "\n",
    "    def set_allow_zero_in_degree(self, set_value):\n",
    "        self._allow_zero_in_degree = set_value\n",
    "\n",
    "    def forward(self, graph, feat, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            if not self._allow_zero_in_degree:\n",
    "                if (graph.in_degrees() == 0).any():\n",
    "                    raise DGLError('There are 0-in-degree nodes in the graph, '\n",
    "                                   'output for those nodes will be invalid. '\n",
    "                                   'This is harmful for some applications, '\n",
    "                                   'causing silent performance regression. '\n",
    "                                   'Adding self-loop on the input graph by '\n",
    "                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n",
    "                                   'the issue. Setting ``allow_zero_in_degree`` '\n",
    "                                   'to be `True` when constructing this module will '\n",
    "                                   'suppress the check and let the code run.')\n",
    "            \n",
    "            if isinstance(feat, tuple):\n",
    "                do_edge_drop = feat[2]\n",
    "                # print('do_edge_drop: ', do_edge_drop)\n",
    "                h_src = self.feat_drop(feat[0])\n",
    "                h_dst = self.feat_drop(feat[1])\n",
    "                h_src2 = h_src.clone()\n",
    "                h_dst2 = h_dst.clone()\n",
    "                if not hasattr(self, 'fc_src'):\n",
    "                    feat_src = self.fc(h_src).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst = self.fc(h_dst).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_src2 = self.fc2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst2 = self.fc2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
    "                else:\n",
    "                    feat_src = self.fc_src(h_src).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst = self.fc_dst(h_dst).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_src2 = self.fc_src2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
    "                    feat_dst2 = self.fc_dst2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
    "            else:\n",
    "                h_src = h_dst = self.feat_drop(feat)\n",
    "                h_src2 = h_dst2 = h_src.clone() # self.feat_drop(feat)\n",
    "                feat_src = feat_dst = self.fc(h_src).view(\n",
    "                    -1, self._num_heads, self._out_feats)\n",
    "                feat_src2 = feat_dst2 = self.fc(h_src).view(\n",
    "                    -1, self._num_heads, self._out_feats)\n",
    "                if graph.is_block:\n",
    "                    feat_dst = feat_src[:graph.number_of_dst_nodes()]\n",
    "                    feat_dst2 = feat_src2[:graph.number_of_dst_nodes()]\n",
    "\n",
    "            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n",
    "            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            graph.srcdata.update({'ft': feat_src, 'el': el, 'feat_src2': feat_src2})\n",
    "            graph.dstdata.update({'er': er, 'feat_dst2': feat_dst2})\n",
    "            # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n",
    "            graph.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
    "            e = self.leaky_relu(graph.edata.pop('e'))\n",
    "            \n",
    "            # compute softmax, edge dropout\n",
    "            if self.training and do_edge_drop and self.edge_drop > 0:\n",
    "                perm = torch.randperm(graph.number_of_edges(), device=e.device)\n",
    "                bound = int(graph.number_of_edges() * self.edge_drop)\n",
    "                eids = perm[bound:]\n",
    "                graph.edata[\"a\"] = torch.zeros_like(e)\n",
    "                graph.edata[\"a\"][eids] = self.attn_drop(edge_softmax(graph, e[eids], eids=eids))\n",
    "            else:\n",
    "                graph.edata['a'] = self.attn_drop(edge_softmax(graph, e))\n",
    "\n",
    "            # message passing\n",
    "            graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n",
    "                             fn.sum('m', 'initial_ft'))\n",
    "            graph.update_all(fn.u_mul_v('feat_src2', 'feat_dst2', 'm2'),\n",
    "                             fn.sum('m2', 'add_ft'))\n",
    "            rst = graph.dstdata['initial_ft'] + graph.dstdata['add_ft']\n",
    "            \n",
    "            # residual\n",
    "            if self.res_fc is not None:\n",
    "                resval = self.res_fc(h_dst).view(h_dst.shape[0], self._num_heads, self._out_feats)\n",
    "                rst = rst + resval\n",
    "            # bias\n",
    "            if self.bias is not None:\n",
    "                rst = rst + self.bias.view(1, self._num_heads, self._out_feats)\n",
    "            # activation\n",
    "            if self.activation:\n",
    "                rst = self.activation(rst)\n",
    "\n",
    "            if get_attention:\n",
    "                return rst, graph.edata['a']\n",
    "            else:\n",
    "                return rst\n",
    "\n",
    "    \n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = 4 # 8\n",
    "        self.hid_feats = int(hid_feats/self.num_heads)\n",
    "        self.out_feats = int(out_feats/self.num_heads)\n",
    "        self.relation_attention = RelationAttention(hid_feats)\n",
    "        \n",
    "        self.gatconv1 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
    "            'i-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'i-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'u-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            'r-u': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
    "            }, aggregate='stack')\n",
    "        \n",
    "        self.gatconv2 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
    "            'i-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'i-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'u-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            'r-u': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
    "            }, aggregate='stack')\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, blocks, inputs, do_edge_drop):\n",
    "        edge_weight_0 = blocks[0].edata['weight']\n",
    "        edge_weight_1 = blocks[1].edata['weight']\n",
    "        \n",
    "        num_users = blocks[-1].dstdata[dgl.NID]['user'].shape[0]\n",
    "        num_recipes = blocks[-1].dstdata[dgl.NID]['recipe'].shape[0]\n",
    "    \n",
    "        h = self.gatconv1(blocks[0], inputs, edge_weight_0, do_edge_drop)\n",
    "        h = {k: F.relu(v).flatten(2) for k, v in h.items()}\n",
    "        h = {k: self.relation_attention(v) for k, v in h.items()} \n",
    "\n",
    "        first_layer_output = {}\n",
    "        first_layer_output['user'] = h['user'][:num_users]\n",
    "        first_layer_output['recipe'] = h['recipe'][:num_recipes]\n",
    "        \n",
    "        h = {key: self.dropout(value) for key, value in h.items()}\n",
    "        h = self.gatconv2(blocks[-1], h, edge_weight_1, do_edge_drop)\n",
    "        last_ingre_and_instr = h['recipe'].flatten(2)\n",
    "        h = {k: self.relation_attention(v.flatten(2)) for k, v in h.items()}\n",
    "\n",
    "        return h\n",
    "    \n",
    "#         # combine several layer embs as the final emb\n",
    "#         combined_output = {}\n",
    "#         combined_output['user'] = torch.cat([h['user'], first_layer_output['user']], dim=1)\n",
    "#         combined_output['recipe'] = torch.cat([h['recipe'], first_layer_output['recipe']], dim=1)\n",
    "#         combined_output['user'] = torch.add(h['user'], first_layer_output['user'])\n",
    "#         combined_output['recipe'] = torch.add(h['recipe'], first_layer_output['recipe'])\n",
    "#         return combined_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(input, p=1, dim=1, eps=1e-12):\n",
    "    return input / input.norm(p, dim, keepdim=True).clamp(min=eps).expand_as(input)\n",
    "\n",
    "def get_recommendation_loss(pos_score, neg_score):\n",
    "    n = pos_score.shape[0]\n",
    "    return (neg_score.view(n, -1) - pos_score.view(n, -1) + 1).clamp(min=0).mean()\n",
    "\n",
    "def get_contrastive_loss(x1, x2):\n",
    "    temperature = 0.07\n",
    "    \n",
    "    # users\n",
    "    x1_user, x2_user = F.normalize(x1['user']), F.normalize(x2['user'])\n",
    "    pos_score_user = torch.mul(x1_user, x2_user).sum(dim=1)\n",
    "    pos_score_user = torch.exp(pos_score_user/temperature)\n",
    "\n",
    "    x2_user_neg = torch.flipud(x2_user)\n",
    "    ttl_score_user = torch.mul(x1_user, x2_user_neg).sum(dim=1)\n",
    "    ttl_score_user = pos_score_user + torch.exp(ttl_score_user/temperature)\n",
    "    \n",
    "    contrastive_loss_user = - torch.log(pos_score_user/ttl_score_user).mean()\n",
    "    # print('contrastive_loss_user: ', contrastive_loss_user)\n",
    "    assert not math.isnan(contrastive_loss_user)\n",
    "\n",
    "    \n",
    "    # recipes\n",
    "    x1_recipe, x2_recipe = F.normalize(x1['recipe']), F.normalize(x2['recipe'])\n",
    "    pos_score_recipe = torch.mul(x1_recipe, x2_recipe).sum(dim=1)\n",
    "    pos_score_recipe = torch.exp(pos_score_recipe/temperature)\n",
    "\n",
    "    x2_recipe_neg = torch.flipud(x2_recipe)\n",
    "    ttl_score_recipe = torch.mul(x1_recipe, x2_recipe_neg).sum(dim=1)\n",
    "    ttl_score_recipe = pos_score_recipe + torch.exp(ttl_score_recipe/temperature) #.sum(dim=1)\n",
    "    \n",
    "    contrastive_loss_recipe = - torch.log(pos_score_recipe/ttl_score_recipe).mean()\n",
    "    # print('contrastive_loss_recipe: ', contrastive_loss_recipe)\n",
    "    \n",
    "    return contrastive_loss_user + contrastive_loss_recipe\n",
    "    \n",
    "def get_emb_loss(*params):\n",
    "    out = None\n",
    "    for param in params:\n",
    "        for k,v in param.items():\n",
    "            if out == None:\n",
    "                out = (v**2/2).mean()\n",
    "            else:\n",
    "                out += (v**2/2).mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Sequential(\n",
    "            nn.Linear(300, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.instr_embedding = nn.Sequential(\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.ingredient_embedding = nn.Sequential(\n",
    "            nn.Linear(46, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.recipe_combine2out = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.gnn = GNN(128, 128, 128, graph.etypes)\n",
    "        self.pred = ScorePredictor()\n",
    "        self.setTransformer_ = SetTransformer()\n",
    "\n",
    "    def forward(self, positive_graph, negative_graph, blocks, input_features):\n",
    "        user, instr, ingredient, ingredient_of_dst_recipe = input_features\n",
    "        \n",
    "        # major GNN\n",
    "        user_major = self.user_embedding(user)\n",
    "        user_major = norm(user_major)\n",
    "        instr_major = self.instr_embedding(instr)\n",
    "        instr_major = norm(instr_major)\n",
    "        ingredient_major = self.ingredient_embedding(ingredient)\n",
    "        ingredient_major = norm(ingredient_major)\n",
    "        x = self.gnn(blocks, {'user': user_major, 'recipe': instr_major, 'ingredient': ingredient_major}, torch.Tensor([[0]]))\n",
    "        \n",
    "        # contrastive - 1\n",
    "        user1 = node_drop(user, 0.1, model.training)\n",
    "        instr1 = node_drop(instr, 0.1, model.training)\n",
    "        ingredient1 = node_drop(ingredient, 0.1, model.training)\n",
    "\n",
    "        user1 = self.user_embedding(user1)\n",
    "        user1 = norm(user1)\n",
    "        instr1 = self.instr_embedding(instr1)\n",
    "        instr1 = norm(instr1)\n",
    "        ingredient1 = self.ingredient_embedding(ingredient1)\n",
    "        ingredient1 = norm(ingredient1)\n",
    "        \n",
    "        x1 = self.gnn(blocks, {'user': user1, 'recipe': instr1, 'ingredient': ingredient1}, torch.Tensor([[1]]))\n",
    "        \n",
    "        # contrastive - 2\n",
    "        user2 = node_drop(user, 0.1, model.training)\n",
    "        instr2 = node_drop(instr, 0.1, model.training)\n",
    "        ingredient2 = node_drop(ingredient, 0.1, model.training)\n",
    "        \n",
    "        user2 = self.user_embedding(user2)\n",
    "        user2 = norm(user2)\n",
    "        instr2 = self.instr_embedding(instr2)\n",
    "        instr2 = norm(instr2)\n",
    "        ingredient2 = self.ingredient_embedding(ingredient2)\n",
    "        ingredient2 = norm(ingredient2)\n",
    "        \n",
    "        x2 = self.gnn(blocks, {'user': user2, 'recipe': instr2, 'ingredient': ingredient2}, torch.Tensor([[1]]))\n",
    "        \n",
    "        # setTransformer\n",
    "        all_ingre_emb_for_each_recipe = get_ingredient_neighbors_all_embeddings(blocks, blocks[1].dstdata['_ID']['recipe'], ingredient_of_dst_recipe)\n",
    "        all_ingre_emb_for_each_recipe = norm(all_ingre_emb_for_each_recipe)\n",
    "        total_ingre_emb = self.setTransformer_(all_ingre_emb_for_each_recipe) # 1\n",
    "        total_ingre_emb = norm(total_ingre_emb)\n",
    "        \n",
    "        # scores\n",
    "        x['recipe'] = self.recipe_combine2out(total_ingre_emb.add(x['recipe']))\n",
    "        pos_score = self.pred(positive_graph, x)\n",
    "        neg_score = self.pred(negative_graph, x)        \n",
    "\n",
    "        return pos_score, neg_score, x1, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    # Relevance is binary (nonzero is relevant).\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k]\n",
    "    return np.mean(r)\n",
    "\n",
    "def recall_at_k(r, k, all_pos_num):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum(r) / all_pos_num\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    # method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    #         If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def average_precision_at_k(r, Ks):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = []\n",
    "    for k in Ks:\n",
    "        assert k <= len(r)\n",
    "        # print('[precision_at_k(r, i + 1) for i in range(k) if r[i]]: ', [precision_at_k(r, i + 1) for i in range(k) if r[i]])\n",
    "        all_precision_before_k = [precision_at_k(r, i + 1) for i in range(k) if r[i]]\n",
    "        if len(all_precision_before_k) == 0:\n",
    "            all_precision_before_k = [0]\n",
    "        out.append(np.mean(all_precision_before_k))\n",
    "    if not out:\n",
    "        return 0.\n",
    "    # return np.array([np.mean(out)])\n",
    "    return np.array(out)\n",
    "\n",
    "def get_map_at_k(rs, Ks):\n",
    "    # examples:\n",
    "    # average_precision_at_k([1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [5,10])\n",
    "    # average_precision_at_k([0, 0, 1, 0, 0, 0, 0, 0, 0, 1], [5,10])\n",
    "    # get_map_at_k([[1, 1, 0, 1, 0, 1, 0, 0, 0, 1,1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1,1]], [5,10])\n",
    "    out = np.zeros(len(Ks))\n",
    "    for r in rs:\n",
    "        # print('average_precision_at_k: ', average_precision_at_k(r, Ks))\n",
    "        out += average_precision_at_k(r, Ks)/len(rs)\n",
    "    return out\n",
    "    # return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "def get_ranklist_for_one_user(user_poss, user_negs, Ks):\n",
    "    item_scores = {}\n",
    "    n_pos = len(user_poss)\n",
    "    n_neg = len(user_negs)\n",
    "    for i in range(n_pos):\n",
    "        item_scores[i] = user_poss[i]\n",
    "    for i in range(n_neg):\n",
    "        item_scores[i+1] = user_negs[i]\n",
    "        \n",
    "    K_max = max(Ks)\n",
    "    K_max_item_score = heapq.nlargest(K_max, item_scores, key=item_scores.get)\n",
    "    \n",
    "    r = []\n",
    "    for i in K_max_item_score:\n",
    "        if i < n_pos:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    return r\n",
    "\n",
    "def hit_at_k(r, k):\n",
    "    r = np.array(r)[:k]\n",
    "    if np.sum(r) > 0:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def get_mrr(rs):\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "\n",
    "\n",
    "def get_performance_one_user(user_poss, user_negs, Ks):\n",
    "    r = get_ranklist_for_one_user(user_poss, user_negs, Ks)\n",
    "    \n",
    "    precision, recall, ndcg, hit_ratio = [], [], [], []\n",
    "    for K in Ks:\n",
    "        precision.append(precision_at_k(r, K))\n",
    "        # recall.append(recall_at_k(r, K, len(user_poss))) \n",
    "        ndcg.append(ndcg_at_k(r, K))\n",
    "        hit_ratio.append(hit_at_k(r, K))\n",
    "    # return {'precision': np.array(precision), 'recall': np.array(recall),\n",
    "    #         'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r    \n",
    "    return {'precision': np.array(precision), \n",
    "            'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r\n",
    "\n",
    "\n",
    "def get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks):\n",
    "    # all_result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "    #           'hit_ratio': np.zeros(len(Ks))}\n",
    "    all_result = {'hit_ratio': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)), 'precision': np.zeros(len(Ks))}\n",
    "    \n",
    "    rs = []\n",
    "    n_test_users = len(user2pos_score_dict)\n",
    "    \n",
    "    # one specific user\n",
    "    for user in user2pos_score_dict.keys():\n",
    "        user_pos_score = user2pos_score_dict[user]\n",
    "        user_neg_score = user2neg_score_dict[user]\n",
    "        one_result, one_r = get_performance_one_user(user_pos_score, user_neg_score, Ks)\n",
    "        # all_result['recall'] += one_result['recall']/n_test_users\n",
    "        all_result['hit_ratio'] += one_result['hit_ratio']/n_test_users\n",
    "        all_result['ndcg'] += one_result['ndcg']/n_test_users\n",
    "        all_result['precision'] += one_result['precision']/n_test_users\n",
    "        rs.append(one_r)\n",
    "        \n",
    "    # get MRR\n",
    "    # MRR = get_mrr(rs)\n",
    "    # all_result['MRR'] = MRR\n",
    "    \n",
    "    # get MAP\n",
    "    MAP = get_map_at_k(rs, Ks)\n",
    "    all_result['MAP'] = MAP\n",
    "\n",
    "    return all_result\n",
    "    \n",
    "    \n",
    "def evaluate(model, dataloader, multi_metrics=False):\n",
    "    # print('start evaluating ...')\n",
    "    evaluate_start = time.time()\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    epoch_contrastive_loss = 0\n",
    "    iteration_cnt = 0\n",
    "    total_pos_score = torch.tensor([]).to(device)\n",
    "    total_neg_score = torch.tensor([]).to(device)\n",
    "    \n",
    "    # for evaluation\n",
    "    user2pos_score_dict = {}\n",
    "    user2neg_score_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "            blocks = [b.to(device) for b in blocks]\n",
    "            positive_graph = positive_graph.to(device)\n",
    "            negative_graph = negative_graph.to(device)\n",
    "\n",
    "            input_user = blocks[0].srcdata['random_feature']['user']\n",
    "            input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
    "            input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
    "            ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
    "            input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
    "\n",
    "            pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
    "            contrastive_loss = get_contrastive_loss(x1, x2)\n",
    "            total_pos_score = torch.cat([total_pos_score, pos_score])\n",
    "            total_neg_score = torch.cat([total_neg_score, neg_score])\n",
    "\n",
    "            recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
    "            loss = recommendation_loss # + 0.01 * contrastive_loss      \n",
    "            total_loss += recommendation_loss.item()\n",
    "            epoch_contrastive_loss += contrastive_loss.item()\n",
    "            iteration_cnt += 1\n",
    "            \n",
    "            # for evaluation\n",
    "            global_test_users = blocks[1].dstdata['_ID']['user'] # we need to map the user id in subgraph to the whole graph\n",
    "            test_users, test_recipes = positive_graph.edges(etype='u-r')\n",
    "            test_users = test_users.tolist()\n",
    "            test_recipes = test_recipes.tolist()\n",
    "            for index in range(len(test_users)):\n",
    "                test_u = int(global_test_users[test_users[index]])\n",
    "                test_r = int(test_recipes[index])\n",
    "                test_score = float(pos_score[index])\n",
    "                \n",
    "                if test_u not in user2pos_score_dict:\n",
    "                    user2pos_score_dict[test_u] = []\n",
    "                user2pos_score_dict[test_u].append(test_score)\n",
    "                \n",
    "                if test_u not in user2neg_score_dict:\n",
    "                    user2neg_score_dict[test_u] = neg_score[index*n_test_negs:(index+1)*n_test_negs]\n",
    "                \n",
    "            # break\n",
    "            \n",
    "        total_loss /= iteration_cnt\n",
    "        epoch_contrastive_loss /= iteration_cnt\n",
    "        \n",
    "        # metrics\n",
    "        auc = compute_auc(total_pos_score, total_neg_score)\n",
    "        if multi_metrics:\n",
    "            # evaluation_result = get_performance_all_users(total_pos_score, total_neg_score, Ks)\n",
    "            evaluation_result = get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks)\n",
    "            evaluation_result['AUC'] = auc\n",
    "            print('evaluation_result: ', evaluation_result)\n",
    "            print('epoch_contrastive_loss: ', epoch_contrastive_loss)\n",
    "        else:\n",
    "            print('AUC: ', auc)\n",
    "        \n",
    "        evalutate_time = time.strftime(\"%M:%S min\", time.gmtime(time.time()-evaluate_start))\n",
    "        print('evalutate_time: ', evalutate_time)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ... \n",
      "Epoch: 0,  Loss: 0.6453, Contrastive: 0.2165, Emb: 0.0000,  Time: 05:21 min, LR: 0.005000\n",
      "Epoch: 1,  Loss: 0.4855, Contrastive: 0.0600, Emb: 0.0000,  Time: 05:18 min, LR: 0.004500\n",
      "Epoch: 2,  Loss: 0.4451, Contrastive: 0.0357, Emb: 0.0000,  Time: 05:18 min, LR: 0.004050\n",
      "Epoch: 3,  Loss: 0.4167, Contrastive: 0.0295, Emb: 0.0000,  Time: 05:22 min, LR: 0.003645\n",
      "Epoch: 4,  Loss: 0.4036, Contrastive: 0.0264, Emb: 0.0000,  Time: 05:25 min, LR: 0.003281\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.17087574, 0.21811785, 0.25493152, 0.29212213, 0.32491519,\n",
      "       0.35067219, 0.37454454, 0.39803995, 0.41939942, 0.43925116]), 'ndcg': array([0.17087574, 0.21811785, 0.24134469, 0.25993999, 0.2740632 ,\n",
      "       0.28402737, 0.29253087, 0.30036267, 0.30710084, 0.31307681]), 'precision': array([0.17087574, 0.10905893, 0.08497717, 0.07303053, 0.06498304,\n",
      "       0.05844537, 0.05350636, 0.04975499, 0.04659994, 0.04392512]), 'MAP': array([0.17087574, 0.1944968 , 0.20676802, 0.21606567, 0.22262428,\n",
      "       0.22691712, 0.23032745, 0.23326438, 0.23563765, 0.23762283]), 'AUC': 0.7779082127951233}\n",
      "epoch_contrastive_loss:  0.022939128771660818\n",
      "evalutate_time:  06:14 min\n",
      "\n",
      "\n",
      "Epoch: 5,  Loss: 0.3909, Contrastive: 0.0228, Emb: 0.0000,  Time: 05:24 min, LR: 0.002952\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16974494, 0.21698706, 0.25292122, 0.28370398, 0.31385852,\n",
      "       0.34263098, 0.36838799, 0.39288855, 0.4156301 , 0.43435105]), 'ndcg': array([0.16974494, 0.21698706, 0.23965899, 0.25505037, 0.26803723,\n",
      "       0.27916793, 0.28834276, 0.29650962, 0.30368378, 0.30931934]), 'precision': array([0.16974494, 0.10849353, 0.08430707, 0.070926  , 0.0627717 ,\n",
      "       0.05710516, 0.05262686, 0.04911107, 0.04618112, 0.0434351 ]), 'MAP': array([0.16974494, 0.193366  , 0.20534405, 0.21303975, 0.21907065,\n",
      "       0.22386606, 0.22754564, 0.23060821, 0.23313505, 0.23500714]), 'AUC': 0.7708175184824361}\n",
      "epoch_contrastive_loss:  0.01884633568780763\n",
      "evalutate_time:  06:25 min\n",
      "\n",
      "\n",
      "Epoch: 6,  Loss: 0.3821, Contrastive: 0.0211, Emb: 0.0000,  Time: 05:52 min, LR: 0.002657\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16974494, 0.21384596, 0.24965448, 0.28382963, 0.31360724,\n",
      "       0.34212841, 0.36763412, 0.3918834 , 0.41613268, 0.43661264]), 'ndcg': array([0.16974494, 0.21384596, 0.23643862, 0.25352619, 0.26635071,\n",
      "       0.27738421, 0.28646953, 0.29455262, 0.30220242, 0.3083675 ]), 'precision': array([0.16974494, 0.10692298, 0.08321816, 0.07095741, 0.06272145,\n",
      "       0.0570214 , 0.05251916, 0.04898543, 0.04623696, 0.04366126]), 'MAP': array([0.16974494, 0.19179545, 0.20373162, 0.21227541, 0.21823093,\n",
      "       0.22298446, 0.22662814, 0.2296593 , 0.23235366, 0.23440166]), 'AUC': 0.765798318909856}\n",
      "epoch_contrastive_loss:  0.01825559554651143\n",
      "evalutate_time:  06:29 min\n",
      "\n",
      "\n",
      "Epoch: 7,  Loss: 0.3750, Contrastive: 0.0196, Emb: 0.0000,  Time: 05:42 min, LR: 0.002391\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.17125267, 0.22289232, 0.26221887, 0.29312728, 0.32303053,\n",
      "       0.3464003 , 0.3732881 , 0.39590401, 0.42065586, 0.44126147]), 'ndcg': array([0.17125267, 0.22289232, 0.24770461, 0.26315882, 0.27603745,\n",
      "       0.28507811, 0.29465573, 0.30219437, 0.31000271, 0.31620562]), 'precision': array([0.17125267, 0.11144616, 0.08740629, 0.07328182, 0.06460611,\n",
      "       0.05773338, 0.05332687, 0.049488  , 0.04673954, 0.04412615]), 'MAP': array([0.17125267, 0.1970725 , 0.21018135, 0.21790845, 0.2238891 ,\n",
      "       0.22778406, 0.23162517, 0.23445216, 0.23720237, 0.23926293]), 'AUC': 0.7752521924107185}\n",
      "epoch_contrastive_loss:  0.01785222262084957\n",
      "evalutate_time:  06:30 min\n",
      "\n",
      "\n",
      "Epoch: 8,  Loss: 0.3697, Contrastive: 0.0185, Emb: 0.0000,  Time: 05:54 min, LR: 0.002152\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.17326297, 0.22163588, 0.26045986, 0.29476065, 0.32491519,\n",
      "       0.3567031 , 0.38308833, 0.40796582, 0.43347154, 0.45005654]), 'ndcg': array([0.17326297, 0.22163588, 0.24613108, 0.26328148, 0.27626833,\n",
      "       0.28856558, 0.29796418, 0.30625668, 0.31430284, 0.31929542]), 'precision': array([0.17326297, 0.11081794, 0.08681995, 0.07369016, 0.06498304,\n",
      "       0.05945052, 0.0547269 , 0.05099573, 0.0481635 , 0.04500565]), 'MAP': array([0.17326297, 0.19744943, 0.21039075, 0.21896595, 0.22499686,\n",
      "       0.23029484, 0.23406416, 0.23717385, 0.24000782, 0.24166632]), 'AUC': 0.7757961653297247}\n",
      "epoch_contrastive_loss:  0.015410453362006044\n",
      "evalutate_time:  06:36 min\n",
      "\n",
      "\n",
      "Epoch: 9,  Loss: 0.3603, Contrastive: 0.0171, Emb: 0.0000,  Time: 05:49 min, LR: 0.001937\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.17225782, 0.22012816, 0.25669054, 0.28998618, 0.3215228 ,\n",
      "       0.34891318, 0.37554969, 0.40168363, 0.4230431 , 0.445659  ]), 'ndcg': array([0.17225782, 0.22012816, 0.24319645, 0.25984427, 0.27342636,\n",
      "       0.2840224 , 0.29351052, 0.30222183, 0.30895999, 0.31576806]), 'precision': array([0.17225782, 0.11006408, 0.08556351, 0.07249654, 0.06430456,\n",
      "       0.0581522 , 0.05364996, 0.05021045, 0.04700479, 0.0445659 ]), 'MAP': array([0.17225782, 0.19619299, 0.20838045, 0.21670436, 0.22301168,\n",
      "       0.22757675, 0.23138196, 0.23464871, 0.23702198, 0.23928357]), 'AUC': 0.773108397240216}\n",
      "epoch_contrastive_loss:  0.013983173820648401\n",
      "evalutate_time:  06:32 min\n",
      "\n",
      "\n",
      "Epoch: 10,  Loss: 0.3563, Contrastive: 0.0164, Emb: 0.0000,  Time: 05:43 min, LR: 0.001743\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16748335, 0.21598191, 0.25442895, 0.28697072, 0.32127152,\n",
      "       0.34803367, 0.37467018, 0.39766302, 0.42103279, 0.43962809]), 'ndcg': array([0.16748335, 0.21598191, 0.24023929, 0.25651018, 0.27128272,\n",
      "       0.28163574, 0.29112386, 0.29878814, 0.30616048, 0.31175822]), 'precision': array([0.16748335, 0.10799095, 0.08480965, 0.07174268, 0.0642543 ,\n",
      "       0.05800561, 0.05352431, 0.04970788, 0.04678142, 0.04396281]), 'MAP': array([0.16748335, 0.19173263, 0.20454831, 0.21268375, 0.21954391,\n",
      "       0.22400427, 0.22780949, 0.23068359, 0.23328023, 0.23513976]), 'AUC': 0.7718590149026893}\n",
      "epoch_contrastive_loss:  0.012969247250270748\n",
      "evalutate_time:  06:07 min\n",
      "\n",
      "\n",
      "Epoch: 11,  Loss: 0.3517, Contrastive: 0.0156, Emb: 0.0000,  Time: 05:20 min, LR: 0.001569\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16811157, 0.2213846 , 0.26247016, 0.29727353, 0.32742807,\n",
      "       0.35431587, 0.38195753, 0.40809147, 0.43095866, 0.45219249]), 'ndcg': array([0.16811157, 0.2213846 , 0.2473067 , 0.26470838, 0.27769524,\n",
      "       0.28809686, 0.29794302, 0.30665433, 0.31386813, 0.32026015]), 'precision': array([0.16811157, 0.1106923 , 0.08749005, 0.07431838, 0.06548561,\n",
      "       0.05905264, 0.05456536, 0.05101143, 0.0478843 , 0.04521925]), 'MAP': array([0.16811157, 0.19474808, 0.20844327, 0.21714411, 0.22317502,\n",
      "       0.22765632, 0.23160513, 0.23487187, 0.23741267, 0.23953605]), 'AUC': 0.7748247475625054}\n",
      "epoch_contrastive_loss:  0.01385661538335539\n",
      "evalutate_time:  06:07 min\n",
      "\n",
      "\n",
      "Epoch: 12,  Loss: 0.3469, Contrastive: 0.0156, Emb: 0.0000,  Time: 05:19 min, LR: 0.001412\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.17188089, 0.21598191, 0.25266993, 0.28621686, 0.31586883,\n",
      "       0.34338485, 0.36876492, 0.39276291, 0.41248901, 0.43284332]), 'ndcg': array([0.17188089, 0.21598191, 0.23912947, 0.25590294, 0.26867335,\n",
      "       0.27931799, 0.28835856, 0.29635789, 0.30258078, 0.30870804]), 'precision': array([0.17188089, 0.10799095, 0.08422331, 0.07155422, 0.06317377,\n",
      "       0.05723081, 0.0526807 , 0.04909536, 0.04583211, 0.04328433]), 'MAP': array([0.17188089, 0.1939314 , 0.20616074, 0.21454747, 0.22047787,\n",
      "       0.22506387, 0.22868959, 0.23168934, 0.23388113, 0.23591656]), 'AUC': 0.771564224481224}\n",
      "epoch_contrastive_loss:  0.01228465267737943\n",
      "evalutate_time:  06:06 min\n",
      "\n",
      "\n",
      "Epoch: 13,  Loss: 0.3430, Contrastive: 0.0150, Emb: 0.0000,  Time: 05:18 min, LR: 0.001271\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.167609  , 0.22176153, 0.25669054, 0.29325292, 0.32240231,\n",
      "       0.35142606, 0.37655484, 0.40168363, 0.42681241, 0.44327177]), 'ndcg': array([0.167609  , 0.22176153, 0.24379928, 0.26208047, 0.27463443,\n",
      "       0.28586235, 0.2948134 , 0.30318966, 0.31111691, 0.31607167]), 'precision': array([0.167609  , 0.11088076, 0.08556351, 0.07331323, 0.06448046,\n",
      "       0.05857101, 0.05379355, 0.05021045, 0.0474236 , 0.04432718]), 'MAP': array([0.167609  , 0.19468526, 0.20632827, 0.21546886, 0.22129874,\n",
      "       0.22613603, 0.22972586, 0.23286696, 0.23565904, 0.23730498]), 'AUC': 0.7741569579147787}\n",
      "epoch_contrastive_loss:  0.01182007629217373\n",
      "evalutate_time:  06:07 min\n",
      "\n",
      "\n",
      "Epoch: 14,  Loss: 0.3383, Contrastive: 0.0146, Emb: 0.0000,  Time: 05:18 min, LR: 0.001144\n",
      "testing: \n",
      "Epoch: 15,  Loss: 0.3368, Contrastive: 0.0138, Emb: 0.0000,  Time: 05:22 min, LR: 0.001029\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16861415, 0.21924865, 0.25870084, 0.29136826, 0.32252796,\n",
      "       0.35217992, 0.37818821, 0.40344264, 0.42492775, 0.44779495]), 'ndcg': array([0.16861415, 0.21924865, 0.24414021, 0.26047392, 0.27389367,\n",
      "       0.28536462, 0.29462896, 0.3030471 , 0.3098249 , 0.31670861]), 'precision': array([0.16861415, 0.10962432, 0.08623361, 0.07284207, 0.06450559,\n",
      "       0.05869665, 0.05402689, 0.05043033, 0.04721419, 0.04477949]), 'MAP': array([0.16861415, 0.1939314 , 0.20708213, 0.21524898, 0.22148092,\n",
      "       0.22642292, 0.23013839, 0.23329519, 0.23568243, 0.23796915]), 'AUC': 0.7757565604196441}\n",
      "epoch_contrastive_loss:  0.010663904234885222\n",
      "evalutate_time:  06:12 min\n",
      "\n",
      "\n",
      "Epoch: 16,  Loss: 0.3321, Contrastive: 0.0136, Emb: 0.0000,  Time: 05:25 min, LR: 0.000927\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16873979, 0.21849479, 0.25493152, 0.28986054, 0.31762784,\n",
      "       0.34376178, 0.37379068, 0.39829124, 0.42140972, 0.44214097]), 'ndcg': array([0.16873979, 0.21849479, 0.24148381, 0.25894831, 0.27090704,\n",
      "       0.28101703, 0.29171354, 0.29988039, 0.30717346, 0.31341419]), 'precision': array([0.16873979, 0.10924739, 0.08497717, 0.07246513, 0.06352557,\n",
      "       0.05729363, 0.05339867, 0.04978641, 0.0468233 , 0.0442141 ]), 'MAP': array([0.16873979, 0.19361729, 0.20576287, 0.21449512, 0.22004858,\n",
      "       0.22440424, 0.22869408, 0.23175665, 0.23432537, 0.2363985 ]), 'AUC': 0.7753827542717553}\n",
      "epoch_contrastive_loss:  0.010579316584866435\n",
      "evalutate_time:  06:14 min\n",
      "\n",
      "\n",
      "Epoch: 17,  Loss: 0.3297, Contrastive: 0.0132, Emb: 0.0000,  Time: 05:27 min, LR: 0.000834\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.1664782 , 0.21736399, 0.25681618, 0.2894836 , 0.32303053,\n",
      "       0.3515517 , 0.37554969, 0.39866817, 0.42178666, 0.44377434]), 'ndcg': array([0.1664782 , 0.21736399, 0.24225555, 0.25858926, 0.27303714,\n",
      "       0.28407063, 0.29261889, 0.30032505, 0.30761812, 0.31423707]), 'precision': array([0.1664782 , 0.108682  , 0.08560539, 0.0723709 , 0.06460611,\n",
      "       0.05859195, 0.05364996, 0.04983352, 0.04686518, 0.04437743]), 'MAP': array([0.1664782 , 0.1919211 , 0.20507183, 0.21323868, 0.21994807,\n",
      "       0.2247016 , 0.22812988, 0.23101969, 0.23358841, 0.23578718]), 'AUC': 0.7754670398128642}\n",
      "epoch_contrastive_loss:  0.010290147278398748\n",
      "evalutate_time:  06:15 min\n",
      "\n",
      "\n",
      "Epoch: 18,  Loss: 0.3255, Contrastive: 0.0137, Emb: 0.0000,  Time: 05:27 min, LR: 0.000750\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16283453, 0.21761528, 0.26096243, 0.2937555 , 0.32654856,\n",
      "       0.35318507, 0.38132931, 0.40909662, 0.43171253, 0.45457972]), 'ndcg': array([0.16283453, 0.21761528, 0.24496429, 0.26136082, 0.27548402,\n",
      "       0.28578843, 0.29581361, 0.30506938, 0.31220391, 0.31908762]), 'precision': array([0.16283453, 0.10880764, 0.08698748, 0.07343887, 0.06530971,\n",
      "       0.05886418, 0.05447562, 0.05113708, 0.04796806, 0.04545797]), 'MAP': array([0.16283453, 0.1902249 , 0.20467395, 0.21287222, 0.21943083,\n",
      "       0.22387025, 0.22789086, 0.23136177, 0.23387465, 0.23616137]), 'AUC': 0.7790184843067673}\n",
      "epoch_contrastive_loss:  0.010333969010158426\n",
      "evalutate_time:  06:16 min\n",
      "\n",
      "\n",
      "Epoch: 19,  Loss: 0.3244, Contrastive: 0.0133, Emb: 0.0000,  Time: 05:30 min, LR: 0.000675\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16811157, 0.22314361, 0.26045986, 0.29275035, 0.3246639 ,\n",
      "       0.35456716, 0.3784395 , 0.40595552, 0.43007916, 0.45231813]), 'ndcg': array([0.16811157, 0.22314361, 0.24668754, 0.26283279, 0.27657721,\n",
      "       0.28814536, 0.29664886, 0.30582087, 0.31343103, 0.32012563]), 'precision': array([0.16811157, 0.11157181, 0.08681995, 0.07318759, 0.06493278,\n",
      "       0.05909453, 0.05406279, 0.05074444, 0.04778657, 0.04523181]), 'MAP': array([0.16811157, 0.19562759, 0.20806634, 0.21613896, 0.22252167,\n",
      "       0.22750555, 0.23091588, 0.23435539, 0.23703579, 0.23925969]), 'AUC': 0.7738842483988767}\n",
      "epoch_contrastive_loss:  0.010344869508925412\n",
      "evalutate_time:  06:18 min\n",
      "\n",
      "\n",
      "Epoch: 20,  Loss: 0.3222, Contrastive: 0.0131, Emb: 0.0000,  Time: 05:41 min, LR: 0.000608\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16999623, 0.21937429, 0.25669054, 0.29312728, 0.32416133,\n",
      "       0.35368765, 0.38120367, 0.40595552, 0.42919965, 0.44980525]), 'ndcg': array([0.16999623, 0.21937429, 0.24291822, 0.26113659, 0.27450223,\n",
      "       0.28592457, 0.29572597, 0.30397659, 0.3113093 , 0.3175122 ]), 'precision': array([0.16999623, 0.10968715, 0.08556351, 0.07328182, 0.06483227,\n",
      "       0.05894794, 0.05445767, 0.05074444, 0.04768885, 0.04498053]), 'MAP': array([0.16999623, 0.19468526, 0.20712401, 0.2162332 , 0.22244001,\n",
      "       0.22736106, 0.23129192, 0.2343859 , 0.23696858, 0.23902914]), 'AUC': 0.7789034553910629}\n",
      "epoch_contrastive_loss:  0.010302472467874252\n",
      "evalutate_time:  06:23 min\n",
      "\n",
      "\n",
      "Epoch: 21,  Loss: 0.3202, Contrastive: 0.0130, Emb: 0.0000,  Time: 05:38 min, LR: 0.000547\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16497047, 0.22163588, 0.25870084, 0.29275035, 0.32755371,\n",
      "       0.3546928 , 0.38183189, 0.40595552, 0.43007916, 0.45282071]), 'ndcg': array([0.16497047, 0.22163588, 0.24502127, 0.26204602, 0.27703501,\n",
      "       0.28753385, 0.29720099, 0.3052422 , 0.31285236, 0.31969824]), 'precision': array([0.16497047, 0.11081794, 0.08623361, 0.07318759, 0.06551074,\n",
      "       0.05911547, 0.05454741, 0.05074444, 0.04778657, 0.04528207]), 'MAP': array([0.16497047, 0.19330318, 0.20565816, 0.21417054, 0.22113121,\n",
      "       0.2256544 , 0.22953141, 0.23254686, 0.23522727, 0.23750142]), 'AUC': 0.7797230208165257}\n",
      "epoch_contrastive_loss:  0.009723533373621722\n",
      "evalutate_time:  06:13 min\n",
      "\n",
      "\n",
      "Epoch: 22,  Loss: 0.3174, Contrastive: 0.0129, Emb: 0.0000,  Time: 05:35 min, LR: 0.000492\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16672949, 0.21937429, 0.25681618, 0.2926247 , 0.32227667,\n",
      "       0.35318507, 0.37944465, 0.40557859, 0.42919965, 0.45093605]), 'ndcg': array([0.16672949, 0.21937429, 0.2429975 , 0.26090175, 0.27367216,\n",
      "       0.28562917, 0.29498302, 0.30369433, 0.31114594, 0.31768925]), 'precision': array([0.16672949, 0.10968715, 0.08560539, 0.07315618, 0.06445533,\n",
      "       0.05886418, 0.05420638, 0.05069732, 0.04768885, 0.0450936 ]), 'MAP': array([0.16672949, 0.19305189, 0.20553252, 0.21448465, 0.22041504,\n",
      "       0.22556644, 0.22931781, 0.23258456, 0.23520912, 0.23738276]), 'AUC': 0.7764477632658175}\n",
      "epoch_contrastive_loss:  0.009929983152283562\n",
      "evalutate_time:  06:14 min\n",
      "\n",
      "\n",
      "Epoch: 23,  Loss: 0.3156, Contrastive: 0.0124, Emb: 0.0000,  Time: 05:39 min, LR: 0.000443\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16346275, 0.21811785, 0.25555974, 0.28923232, 0.32039201,\n",
      "       0.34878754, 0.37479583, 0.39979897, 0.42254052, 0.44528207]), 'ndcg': array([0.16346275, 0.21811785, 0.24174106, 0.25857734, 0.27199709,\n",
      "       0.28298198, 0.29224632, 0.3005807 , 0.30775486, 0.31460075]), 'precision': array([0.16346275, 0.10905893, 0.08518658, 0.07230808, 0.0640784 ,\n",
      "       0.05813126, 0.05354226, 0.04997487, 0.04694895, 0.04452821]), 'MAP': array([0.16346275, 0.1907903 , 0.20327093, 0.21168907, 0.21792101,\n",
      "       0.2226536 , 0.22636907, 0.22949446, 0.2320213 , 0.23429546]), 'AUC': 0.7749070553050017}\n",
      "epoch_contrastive_loss:  0.0093764930054368\n",
      "evalutate_time:  06:25 min\n",
      "\n",
      "\n",
      "Epoch: 24,  Loss: 0.3147, Contrastive: 0.0126, Emb: 0.0000,  Time: 05:42 min, LR: 0.000399\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16459354, 0.21736399, 0.25706747, 0.29300163, 0.32566905,\n",
      "       0.35117477, 0.37793693, 0.40294007, 0.42806885, 0.45282071]), 'ndcg': array([0.16459354, 0.21736399, 0.2424141 , 0.26038118, 0.27445027,\n",
      "       0.28431723, 0.2938501 , 0.30218448, 0.31011173, 0.31756278]), 'precision': array([0.16459354, 0.108682  , 0.08568916, 0.07325041, 0.06513381,\n",
      "       0.05852913, 0.05399099, 0.05036751, 0.04756321, 0.04528207]), 'MAP': array([0.16459354, 0.19097877, 0.20421326, 0.2131968 , 0.21973028,\n",
      "       0.22398124, 0.2278044 , 0.23092979, 0.23372188, 0.23619707]), 'AUC': 0.777670179992224}\n",
      "epoch_contrastive_loss:  0.009774014157878737\n",
      "evalutate_time:  06:16 min\n",
      "\n",
      "\n",
      "Epoch: 25,  Loss: 0.3125, Contrastive: 0.0129, Emb: 0.0000,  Time: 05:40 min, LR: 0.000359\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16534741, 0.21862043, 0.2554341 , 0.29224777, 0.32039201,\n",
      "       0.3484106 , 0.37655484, 0.40231185, 0.42517904, 0.44704109]), 'ndcg': array([0.16534741, 0.21862043, 0.24184727, 0.2602541 , 0.27237517,\n",
      "       0.28321424, 0.29323942, 0.30182509, 0.30903889, 0.31562002]), 'precision': array([0.16534741, 0.10931021, 0.0851447 , 0.07306194, 0.0640784 ,\n",
      "       0.05806843, 0.05379355, 0.05028898, 0.04724212, 0.04470411]), 'MAP': array([0.16534741, 0.19198392, 0.20425514, 0.21345856, 0.21908741,\n",
      "       0.22375717, 0.22777778, 0.2309974 , 0.2335382 , 0.23572441]), 'AUC': 0.7756209541736554}\n",
      "epoch_contrastive_loss:  0.009455204863722125\n",
      "evalutate_time:  06:17 min\n",
      "\n",
      "\n",
      "Epoch: 26,  Loss: 0.3126, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:43 min, LR: 0.000323\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16346275, 0.21924865, 0.2574444 , 0.29199648, 0.32403568,\n",
      "       0.35293379, 0.37755999, 0.40105541, 0.42492775, 0.44779495]), 'ndcg': array([0.16346275, 0.21924865, 0.24334749, 0.26062353, 0.27442206,\n",
      "       0.28560137, 0.2943734 , 0.30220521, 0.3097361 , 0.31661981]), 'precision': array([0.16346275, 0.10962432, 0.0858148 , 0.07299912, 0.06480714,\n",
      "       0.0588223 , 0.05393714, 0.05013193, 0.04721419, 0.04477949]), 'MAP': array([0.16346275, 0.1913557 , 0.20408762, 0.21272564, 0.21913348,\n",
      "       0.22394983, 0.22746786, 0.23040478, 0.23305727, 0.23534399]), 'AUC': 0.7746761639518881}\n",
      "epoch_contrastive_loss:  0.009642346843426663\n",
      "evalutate_time:  06:25 min\n",
      "\n",
      "\n",
      "Epoch: 27,  Loss: 0.3098, Contrastive: 0.0126, Emb: 0.0000,  Time: 05:43 min, LR: 0.000291\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16421661, 0.21849479, 0.25895213, 0.29212213, 0.32441261,\n",
      "       0.34991833, 0.37743435, 0.40344264, 0.42806885, 0.45093605]), 'ndcg': array([0.16421661, 0.21849479, 0.24402053, 0.26060553, 0.27451228,\n",
      "       0.28437924, 0.29418064, 0.30285008, 0.31061878, 0.31750249]), 'precision': array([0.16421661, 0.10924739, 0.08631738, 0.07303053, 0.06488252,\n",
      "       0.05831972, 0.05391919, 0.05043033, 0.04756321, 0.0450936 ]), 'MAP': array([0.16421661, 0.1913557 , 0.20484148, 0.21313398, 0.21959208,\n",
      "       0.22384303, 0.22777389, 0.23102493, 0.23376117, 0.23604789]), 'AUC': 0.7784880243058718}\n",
      "epoch_contrastive_loss:  0.009479393886904868\n",
      "evalutate_time:  06:24 min\n",
      "\n",
      "\n",
      "Epoch: 28,  Loss: 0.3107, Contrastive: 0.0130, Emb: 0.0000,  Time: 05:44 min, LR: 0.000262\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.1613268 , 0.21472547, 0.25455459, 0.29124262, 0.3246639 ,\n",
      "       0.35180299, 0.3784395 , 0.40444779, 0.429074  , 0.45219249]), 'ndcg': array([0.1613268 , 0.21472547, 0.23985485, 0.25819886, 0.27259262,\n",
      "       0.28309146, 0.29257957, 0.301249  , 0.30901771, 0.31597707]), 'precision': array([0.1613268 , 0.10736273, 0.08485153, 0.07281065, 0.06493278,\n",
      "       0.05863383, 0.05406279, 0.05055597, 0.04767489, 0.04521925]), 'MAP': array([0.1613268 , 0.18802613, 0.20130251, 0.21047452, 0.21715877,\n",
      "       0.22168195, 0.22548717, 0.22873821, 0.23147445, 0.2337863 ]), 'AUC': 0.7781184587785867}\n",
      "epoch_contrastive_loss:  0.009266193505258315\n",
      "evalutate_time:  06:22 min\n",
      "\n",
      "\n",
      "Epoch: 29,  Loss: 0.3082, Contrastive: 0.0121, Emb: 0.0000,  Time: 05:43 min, LR: 0.000236\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16534741, 0.21887172, 0.25681618, 0.29450936, 0.32215102,\n",
      "       0.35092348, 0.37592662, 0.40206056, 0.42605855, 0.44892574]), 'ndcg': array([0.16534741, 0.21887172, 0.24281201, 0.2616586 , 0.27356322,\n",
      "       0.28469392, 0.29360022, 0.30231153, 0.30988206, 0.31676577]), 'precision': array([0.16534741, 0.10943586, 0.08560539, 0.07362734, 0.0644302 ,\n",
      "       0.05848725, 0.0537038 , 0.05025757, 0.04733984, 0.04489257]), 'MAP': array([0.16534741, 0.19210956, 0.20475772, 0.21418101, 0.21970934,\n",
      "       0.22450475, 0.22807663, 0.23134337, 0.23400982, 0.23629654]), 'AUC': 0.7760483446377346}\n",
      "epoch_contrastive_loss:  0.00932965436506839\n",
      "evalutate_time:  06:25 min\n",
      "\n",
      "\n",
      "Epoch: 30,  Loss: 0.3081, Contrastive: 0.0121, Emb: 0.0000,  Time: 05:43 min, LR: 0.000212\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16258324, 0.21585626, 0.2565649 , 0.29111697, 0.32516648,\n",
      "       0.35444151, 0.38095238, 0.40633245, 0.42844578, 0.44942832]), 'ndcg': array([0.16258324, 0.21585626, 0.24154055, 0.25881659, 0.27348091,\n",
      "       0.28480604, 0.2942494 , 0.30270943, 0.30968541, 0.31600178]), 'precision': array([0.16258324, 0.10792813, 0.08552163, 0.07277924, 0.0650333 ,\n",
      "       0.05907359, 0.05442177, 0.05079156, 0.04760509, 0.04494283]), 'MAP': array([0.16258324, 0.18921975, 0.2027893 , 0.21142731, 0.21823722,\n",
      "       0.22311639, 0.22690366, 0.23007616, 0.2325332 , 0.23463145]), 'AUC': 0.773458348802028}\n",
      "epoch_contrastive_loss:  0.009302473889427289\n",
      "evalutate_time:  06:23 min\n",
      "\n",
      "\n",
      "Epoch: 31,  Loss: 0.3072, Contrastive: 0.0124, Emb: 0.0000,  Time: 05:45 min, LR: 0.000191\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16170373, 0.21648448, 0.25417766, 0.29325292, 0.32491519,\n",
      "       0.35444151, 0.38132931, 0.40394522, 0.42932529, 0.45068476]), 'ndcg': array([0.16170373, 0.21648448, 0.24026623, 0.25980386, 0.27344006,\n",
      "       0.2848624 , 0.29444003, 0.30197866, 0.30998518, 0.31641502]), 'precision': array([0.16170373, 0.10824224, 0.08472589, 0.07331323, 0.06498304,\n",
      "       0.05907359, 0.05447562, 0.05049315, 0.04770281, 0.04506848]), 'MAP': array([0.16170373, 0.18909411, 0.2016585 , 0.21142731, 0.21775977,\n",
      "       0.22268082, 0.22652194, 0.22934893, 0.23216893, 0.23430488]), 'AUC': 0.7767702304755395}\n",
      "epoch_contrastive_loss:  0.009069942976422017\n",
      "evalutate_time:  06:24 min\n",
      "\n",
      "\n",
      "Epoch: 32,  Loss: 0.3070, Contrastive: 0.0126, Emb: 0.0000,  Time: 05:43 min, LR: 0.000172\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.1633371 , 0.21673577, 0.25945471, 0.29249906, 0.3246639 ,\n",
      "       0.35243121, 0.37806257, 0.40306571, 0.42744063, 0.45055912]), 'ndcg': array([0.1633371 , 0.21673577, 0.24368842, 0.26021059, 0.27406324,\n",
      "       0.2848051 , 0.29393517, 0.30226955, 0.30995899, 0.31691834]), 'precision': array([0.1633371 , 0.10836789, 0.0864849 , 0.07312476, 0.06493278,\n",
      "       0.05873853, 0.05400894, 0.05038321, 0.0474934 , 0.04505591]), 'MAP': array([0.1633371 , 0.19003644, 0.20427608, 0.21253717, 0.21897014,\n",
      "       0.22359802, 0.22725965, 0.23038504, 0.23309336, 0.23540521]), 'AUC': 0.7756900340214198}\n",
      "epoch_contrastive_loss:  0.009388880530697486\n",
      "evalutate_time:  06:20 min\n",
      "\n",
      "\n",
      "Epoch: 33,  Loss: 0.3050, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:40 min, LR: 0.000155\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16396532, 0.21874607, 0.25731876, 0.29249906, 0.32353311,\n",
      "       0.35192863, 0.37806257, 0.40369393, 0.42681241, 0.44842317]), 'ndcg': array([0.16396532, 0.21874607, 0.24308273, 0.26067288, 0.27403852,\n",
      "       0.2850234 , 0.2943325 , 0.30287629, 0.31016936, 0.31667484]), 'precision': array([0.16396532, 0.10937304, 0.08577292, 0.07312476, 0.06470662,\n",
      "       0.05865477, 0.05400894, 0.05046174, 0.0474236 , 0.04484232]), 'MAP': array([0.16396532, 0.1913557 , 0.20421326, 0.21300833, 0.21921514,\n",
      "       0.22394773, 0.22768115, 0.23088507, 0.23345379, 0.23561487]), 'AUC': 0.7754467616347829}\n",
      "epoch_contrastive_loss:  0.00917081904804541\n",
      "evalutate_time:  06:17 min\n",
      "\n",
      "\n",
      "Epoch: 34,  Loss: 0.3049, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:43 min, LR: 0.000139\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16233195, 0.2171127 , 0.25870084, 0.29099133, 0.32428697,\n",
      "       0.35255685, 0.37969594, 0.40432215, 0.42756628, 0.44854881]), 'ndcg': array([0.16233195, 0.2171127 , 0.2433519 , 0.25949714, 0.27383679,\n",
      "       0.28477308, 0.29444021, 0.30264895, 0.30998166, 0.31629803]), 'precision': array([0.16233195, 0.10855635, 0.08623361, 0.07274783, 0.06485739,\n",
      "       0.05875948, 0.05424228, 0.05054027, 0.04750736, 0.04485488]), 'MAP': array([0.16233195, 0.18972233, 0.20358504, 0.21165766, 0.21831679,\n",
      "       0.22302844, 0.22690545, 0.22998373, 0.23256641, 0.23466466]), 'AUC': 0.7763253164805348}\n",
      "epoch_contrastive_loss:  0.009044617218601088\n",
      "evalutate_time:  06:24 min\n",
      "\n",
      "\n",
      "Epoch: 35,  Loss: 0.3046, Contrastive: 0.0124, Emb: 0.0000,  Time: 05:43 min, LR: 0.000125\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.1624576 , 0.21598191, 0.25719311, 0.29086569, 0.32642292,\n",
      "       0.35243121, 0.37781128, 0.40658374, 0.42982787, 0.45370021]), 'ndcg': array([0.1624576 , 0.21598191, 0.24198328, 0.25881957, 0.27413324,\n",
      "       0.28419462, 0.29323518, 0.302826  , 0.31015871, 0.317345  ]), 'precision': array([0.1624576 , 0.10799095, 0.08573104, 0.07271642, 0.06528458,\n",
      "       0.05873853, 0.05397304, 0.05082297, 0.04775865, 0.04537002]), 'MAP': array([0.1624576 , 0.18921975, 0.20295682, 0.21137496, 0.21848641,\n",
      "       0.22282112, 0.22644685, 0.23004341, 0.23262609, 0.23501332]), 'AUC': 0.7761025211016359}\n",
      "epoch_contrastive_loss:  0.00922929516269101\n",
      "evalutate_time:  06:21 min\n",
      "\n",
      "\n",
      "Epoch: 36,  Loss: 0.3035, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:41 min, LR: 0.000113\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16296017, 0.21811785, 0.25643925, 0.29161955, 0.32315618,\n",
      "       0.35205428, 0.37693178, 0.40243749, 0.42618419, 0.44666415]), 'ndcg': array([0.16296017, 0.21811785, 0.24229596, 0.25988611, 0.2734682 ,\n",
      "       0.28464751, 0.29350905, 0.30201096, 0.30950221, 0.31566729]), 'precision': array([0.16296017, 0.10905893, 0.08547975, 0.07290489, 0.06463124,\n",
      "       0.05867571, 0.0538474 , 0.05030469, 0.0473538 , 0.04466642]), 'MAP': array([0.16296017, 0.19053901, 0.20331281, 0.21210789, 0.21841521,\n",
      "       0.22323156, 0.22678549, 0.2299737 , 0.23261223, 0.23466022]), 'AUC': 0.7747796850585599}\n",
      "epoch_contrastive_loss:  0.00899605569799268\n",
      "evalutate_time:  06:17 min\n",
      "\n",
      "\n",
      "Epoch: 37,  Loss: 0.3046, Contrastive: 0.0121, Emb: 0.0000,  Time: 05:41 min, LR: 0.000101\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16409097, 0.21774092, 0.25606232, 0.29023747, 0.32277924,\n",
      "       0.35381329, 0.37793693, 0.40155798, 0.42957658, 0.45043347]), 'ndcg': array([0.16409097, 0.21774092, 0.24191903, 0.25900661, 0.27302159,\n",
      "       0.2850272 , 0.29362021, 0.30149389, 0.31033278, 0.31661133]), 'precision': array([0.16409097, 0.10887046, 0.08535411, 0.07255937, 0.06455585,\n",
      "       0.05896888, 0.05399099, 0.05019475, 0.04773073, 0.04504335]), 'MAP': array([0.16409097, 0.19091594, 0.20368974, 0.21223353, 0.21874189,\n",
      "       0.22391423, 0.22736046, 0.23031309, 0.23342627, 0.23551196]), 'AUC': 0.7752184457532314}\n",
      "epoch_contrastive_loss:  0.008960550392253531\n",
      "evalutate_time:  06:21 min\n",
      "\n",
      "\n",
      "Epoch: 38,  Loss: 0.3039, Contrastive: 0.0122, Emb: 0.0000,  Time: 05:44 min, LR: 0.000091\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16471919, 0.21836914, 0.25706747, 0.29237341, 0.32491519,\n",
      "       0.35180299, 0.37869079, 0.40394522, 0.42806885, 0.45106169]), 'ndcg': array([0.16471919, 0.21836914, 0.24278507, 0.26043804, 0.27445302,\n",
      "       0.28485464, 0.29443227, 0.30285041, 0.31046057, 0.31738211]), 'precision': array([0.16471919, 0.10918457, 0.08568916, 0.07309335, 0.06498304,\n",
      "       0.05863383, 0.05409868, 0.05049315, 0.04756321, 0.04510617]), 'MAP': array([0.16471919, 0.19154416, 0.20444361, 0.21327009, 0.21977845,\n",
      "       0.22425975, 0.22810086, 0.23125767, 0.23393807, 0.23623735]), 'AUC': 0.7761581977467416}\n",
      "epoch_contrastive_loss:  0.009005891643316737\n",
      "evalutate_time:  06:20 min\n",
      "\n",
      "\n",
      "Epoch: 39,  Loss: 0.3017, Contrastive: 0.0122, Emb: 0.0000,  Time: 05:44 min, LR: 0.000082\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16522176, 0.21635884, 0.25530846, 0.2906144 , 0.32353311,\n",
      "       0.35130041, 0.37668049, 0.40206056, 0.4230431 , 0.44829752]), 'ndcg': array([0.16522176, 0.21635884, 0.24093331, 0.25858628, 0.2727636 ,\n",
      "       0.28350546, 0.29254602, 0.30100605, 0.3076253 , 0.31522764]), 'precision': array([0.16522176, 0.10817942, 0.08510282, 0.0726536 , 0.06470662,\n",
      "       0.05855007, 0.0538115 , 0.05025757, 0.04700479, 0.04482975]), 'MAP': array([0.16522176, 0.1907903 , 0.20377351, 0.21259999, 0.21918373,\n",
      "       0.22381162, 0.22743734, 0.23060985, 0.23294124, 0.23546669]), 'AUC': 0.7754188414203014}\n",
      "epoch_contrastive_loss:  0.008994526163275753\n",
      "evalutate_time:  06:23 min\n",
      "\n",
      "\n",
      "Epoch: 40,  Loss: 0.3019, Contrastive: 0.0120, Emb: 0.0000,  Time: 05:43 min, LR: 0.000074\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16258324, 0.2171127 , 0.25807262, 0.29350421, 0.3226536 ,\n",
      "       0.35130041, 0.37567534, 0.40319136, 0.42794321, 0.44967961]), 'ndcg': array([0.16258324, 0.2171127 , 0.24295553, 0.26067133, 0.27322529,\n",
      "       0.28430739, 0.29298991, 0.30216192, 0.30997026, 0.31651357]), 'precision': array([0.16258324, 0.10855635, 0.08602421, 0.07337605, 0.06453072,\n",
      "       0.05855007, 0.05366791, 0.05039892, 0.04754925, 0.04496796]), 'MAP': array([0.16258324, 0.18984797, 0.20350128, 0.21235917, 0.21818905,\n",
      "       0.22296352, 0.22644565, 0.22988516, 0.23263536, 0.234809  ]), 'AUC': 0.776483945290603}\n",
      "epoch_contrastive_loss:  0.009038787556900865\n",
      "evalutate_time:  06:24 min\n",
      "\n",
      "\n",
      "Epoch: 41,  Loss: 0.3026, Contrastive: 0.0122, Emb: 0.0000,  Time: 05:44 min, LR: 0.000067\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16233195, 0.22012816, 0.25782133, 0.29199648, 0.32416133,\n",
      "       0.35243121, 0.37793693, 0.40243749, 0.42806885, 0.45055912]), 'ndcg': array([0.16233195, 0.22012816, 0.2439099 , 0.26099748, 0.27485012,\n",
      "       0.28578641, 0.29487173, 0.30303858, 0.31112437, 0.31789462]), 'precision': array([0.16233195, 0.11006408, 0.08594044, 0.07299912, 0.06483227,\n",
      "       0.05873853, 0.05399099, 0.05030469, 0.04756321, 0.04505591]), 'MAP': array([0.16233195, 0.19123005, 0.20379445, 0.21233823, 0.2187712 ,\n",
      "       0.22348285, 0.22712652, 0.23018909, 0.23303702, 0.23528605]), 'AUC': 0.7752342645901936}\n",
      "epoch_contrastive_loss:  0.009098994375635234\n",
      "evalutate_time:  06:24 min\n",
      "\n",
      "\n",
      "Epoch: 42,  Loss: 0.3013, Contrastive: 0.0120, Emb: 0.0000,  Time: 05:43 min, LR: 0.000060\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16421661, 0.21924865, 0.25694183, 0.29174519, 0.32290489,\n",
      "       0.35104913, 0.37705742, 0.40306571, 0.42693806, 0.45055912]), 'ndcg': array([0.16421661, 0.21924865, 0.2430304 , 0.26043208, 0.27385183,\n",
      "       0.28473951, 0.29400385, 0.30267328, 0.31020417, 0.31731481]), 'precision': array([0.16421661, 0.10962432, 0.08564728, 0.0729363 , 0.06458098,\n",
      "       0.05850819, 0.05386535, 0.05038321, 0.04743756, 0.04505591]), 'MAP': array([0.16421661, 0.19173263, 0.20429702, 0.21299786, 0.2192298 ,\n",
      "       0.22392051, 0.22763598, 0.23088702, 0.2335395 , 0.2359016 ]), 'AUC': 0.7760527665650954}\n",
      "epoch_contrastive_loss:  0.009019496381312372\n",
      "evalutate_time:  06:20 min\n",
      "\n",
      "\n",
      "Epoch: 43,  Loss: 0.3014, Contrastive: 0.0120, Emb: 0.0000,  Time: 05:42 min, LR: 0.000054\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16057294, 0.21598191, 0.25216736, 0.28998618, 0.3206433 ,\n",
      "       0.3495414 , 0.37504712, 0.40344264, 0.429074  , 0.45118734]), 'ndcg': array([0.16057294, 0.21598191, 0.23881238, 0.2577218 , 0.2709251 ,\n",
      "       0.28210441, 0.29118973, 0.3006549 , 0.3087407 , 0.31539747]), 'precision': array([0.16057294, 0.10799095, 0.08405579, 0.07249654, 0.06412866,\n",
      "       0.0582569 , 0.05357816, 0.05043033, 0.04767489, 0.04511873]), 'MAP': array([0.16057294, 0.18827742, 0.20033924, 0.20979394, 0.21592537,\n",
      "       0.22074172, 0.22438539, 0.22793483, 0.23078276, 0.23299409]), 'AUC': 0.7764589579516874}\n",
      "epoch_contrastive_loss:  0.009092770128821334\n",
      "evalutate_time:  06:16 min\n",
      "\n",
      "\n",
      "Epoch: 44,  Loss: 0.3024, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:40 min, LR: 0.000048\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16220631, 0.21673577, 0.25493152, 0.29161955, 0.32541777,\n",
      "       0.35192863, 0.37705742, 0.40381958, 0.42869707, 0.45093605]), 'ndcg': array([0.16220631, 0.21673577, 0.24083461, 0.25917862, 0.27373472,\n",
      "       0.28399052, 0.29294158, 0.3018623 , 0.30971027, 0.31640487]), 'precision': array([0.16220631, 0.10836789, 0.08497717, 0.07290489, 0.06508355,\n",
      "       0.05865477, 0.05386535, 0.05047745, 0.04763301, 0.0450936 ]), 'MAP': array([0.16220631, 0.18947104, 0.20220296, 0.21137496, 0.21813461,\n",
      "       0.22255308, 0.22614291, 0.22948818, 0.23225235, 0.23447624]), 'AUC': 0.7777077349598627}\n",
      "epoch_contrastive_loss:  0.00901691172833717\n",
      "evalutate_time:  06:18 min\n",
      "\n",
      "\n",
      "Epoch: 45,  Loss: 0.3019, Contrastive: 0.0123, Emb: 0.0000,  Time: 05:41 min, LR: 0.000044\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16459354, 0.21748963, 0.25555974, 0.29124262, 0.32340746,\n",
      "       0.35406458, 0.37781128, 0.40168363, 0.42530469, 0.45093605]), 'ndcg': array([0.16459354, 0.21748963, 0.2415092 , 0.25935064, 0.27320328,\n",
      "       0.28506307, 0.29352182, 0.30147927, 0.30893088, 0.31664669]), 'precision': array([0.16459354, 0.10874482, 0.08518658, 0.07281065, 0.06468149,\n",
      "       0.05901076, 0.05397304, 0.05021045, 0.04725608, 0.0450936 ]), 'MAP': array([0.16459354, 0.19104159, 0.20373162, 0.21265234, 0.21908531,\n",
      "       0.22419483, 0.22758722, 0.23057126, 0.23319582, 0.23575896]), 'AUC': 0.7759983531473913}\n",
      "epoch_contrastive_loss:  0.009010166539588855\n",
      "evalutate_time:  06:32 min\n",
      "\n",
      "\n",
      "Epoch: 46,  Loss: 0.3012, Contrastive: 0.0124, Emb: 0.0000,  Time: 05:52 min, LR: 0.000039\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16233195, 0.21610755, 0.25530846, 0.29074004, 0.32189974,\n",
      "       0.35104913, 0.37793693, 0.40168363, 0.42806885, 0.45093605]), 'ndcg': array([0.16233195, 0.21610755, 0.24084057, 0.25855636, 0.27197611,\n",
      "       0.28325263, 0.29283026, 0.30074583, 0.30906944, 0.31595315]), 'precision': array([0.16233195, 0.10805378, 0.08510282, 0.07268501, 0.06437995,\n",
      "       0.05850819, 0.05399099, 0.05021045, 0.04756321, 0.0450936 ]), 'MAP': array([0.16233195, 0.18921975, 0.20228672, 0.21114462, 0.21737655,\n",
      "       0.22223479, 0.2260759 , 0.22904424, 0.23197593, 0.23426265]), 'AUC': 0.7754347964938604}\n",
      "epoch_contrastive_loss:  0.008972677542635846\n",
      "evalutate_time:  06:32 min\n",
      "\n",
      "\n",
      "Epoch: 47,  Loss: 0.2993, Contrastive: 0.0121, Emb: 0.0000,  Time: 05:51 min, LR: 0.000035\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16157809, 0.21573062, 0.25618796, 0.29287599, 0.32290489,\n",
      "       0.35054655, 0.37705742, 0.40168363, 0.42618419, 0.45005654]), 'ndcg': array([0.16157809, 0.21573062, 0.24125636, 0.25960037, 0.27253312,\n",
      "       0.28322637, 0.29266973, 0.30087847, 0.30860754, 0.31579383]), 'precision': array([0.16157809, 0.10786531, 0.08539599, 0.073219  , 0.06458098,\n",
      "       0.05842443, 0.05386535, 0.05021045, 0.0473538 , 0.04500565]), 'MAP': array([0.16157809, 0.18865435, 0.20214013, 0.21131214, 0.21731792,\n",
      "       0.22192486, 0.22571213, 0.22879041, 0.23151269, 0.23389993]), 'AUC': 0.775936662201169}\n",
      "epoch_contrastive_loss:  0.009003491140902042\n",
      "evalutate_time:  06:31 min\n",
      "\n",
      "\n",
      "Epoch: 48,  Loss: 0.3002, Contrastive: 0.0125, Emb: 0.0000,  Time: 05:52 min, LR: 0.000032\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16157809, 0.2162332 , 0.25317251, 0.29074004, 0.32277924,\n",
      "       0.34991833, 0.37655484, 0.4021862 , 0.42618419, 0.45256942]), 'ndcg': array([0.16157809, 0.2162332 , 0.23953931, 0.25832307, 0.27212161,\n",
      "       0.28262044, 0.29210856, 0.30065234, 0.30822287, 0.31616561]), 'precision': array([0.16157809, 0.1081166 , 0.08439084, 0.07268501, 0.06455585,\n",
      "       0.05831972, 0.05379355, 0.05027328, 0.0473538 , 0.04525694]), 'MAP': array([0.16157809, 0.18890564, 0.20121875, 0.21061063, 0.21701847,\n",
      "       0.22154165, 0.22534687, 0.22855079, 0.23121723, 0.23385575]), 'AUC': 0.775743317054244}\n",
      "epoch_contrastive_loss:  0.008927934086098084\n",
      "evalutate_time:  06:29 min\n",
      "\n",
      "\n",
      "Epoch: 49,  Loss: 0.3015, Contrastive: 0.0120, Emb: 0.0000,  Time: 05:48 min, LR: 0.000029\n",
      "testing: \n",
      "evaluation_result:  {'hit_ratio': array([0.16283453, 0.21698706, 0.25329815, 0.29011182, 0.32277924,\n",
      "       0.35067219, 0.37705742, 0.40155798, 0.42543033, 0.4499309 ]), 'ndcg': array([0.16283453, 0.21698706, 0.23989681, 0.25830364, 0.27237274,\n",
      "       0.2831632 , 0.29256181, 0.30072866, 0.30825955, 0.31563496]), 'precision': array([0.16283453, 0.10849353, 0.08443272, 0.07252796, 0.06455585,\n",
      "       0.05844537, 0.05386535, 0.05019475, 0.04727004, 0.04499309]), 'MAP': array([0.16283453, 0.18991079, 0.20201449, 0.21121791, 0.21775139,\n",
      "       0.22240022, 0.22616954, 0.22923211, 0.23188459, 0.23433465]), 'AUC': 0.7764728484803881}\n",
      "epoch_contrastive_loss:  0.008916497256399857\n",
      "evalutate_time:  06:21 min\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.9)\n",
    "\n",
    "print('start ... ')\n",
    "for epoch in range(50):\n",
    "    train_start = time.time()\n",
    "    epoch_loss = 0\n",
    "    epoch_contrastive_loss = 0\n",
    "    epoch_emb_loss = 0\n",
    "    iteration_cnt = 0\n",
    "    \n",
    "    for input_nodes, positive_graph, negative_graph, blocks in train_edgeloader:\n",
    "        model.train()\n",
    "        blocks = [b.to(device) for b in blocks]\n",
    "        positive_graph = positive_graph.to(device)\n",
    "        negative_graph = negative_graph.to(device)\n",
    "        \n",
    "        input_user = blocks[0].srcdata['random_feature']['user']\n",
    "        input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
    "        input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
    "        ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
    "        input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
    "        \n",
    "        pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
    "        contrastive_loss = get_contrastive_loss(x1, x2)\n",
    "        # emb_loss = get_emb_loss(x1, x2)\n",
    "        assert not math.isnan(contrastive_loss)        \n",
    "        recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
    "        assert not math.isnan(recommendation_loss)\n",
    "        \n",
    "        loss = recommendation_loss + 0.1 * contrastive_loss # + 1e-5 * emb_loss\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        epoch_loss += recommendation_loss.item()\n",
    "        epoch_contrastive_loss += contrastive_loss.item()\n",
    "        # epoch_emb_loss += emb_loss.item()\n",
    "        iteration_cnt += 1\n",
    "\n",
    "        # break\n",
    "        \n",
    "    epoch_loss /= iteration_cnt\n",
    "    epoch_contrastive_loss /= iteration_cnt\n",
    "    train_end = time.strftime(\"%M:%S min\", time.gmtime(time.time()-train_start))\n",
    "    \n",
    "    print('Epoch: {0},  Loss: {l:.4f}, Contrastive: {cl:.4f}, Emb: {el:.4f},  Time: {t}, LR: {lr:.6f}'\n",
    "          .format(epoch, l=epoch_loss, cl=epoch_contrastive_loss, el=epoch_emb_loss, t=train_end, lr=opt.param_groups[0]['lr']))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    # For demonstration purpose, only test set result is reported here. Please use val_dataloader for comprehensiveness.\n",
    "    if epoch >= 4 and epoch % 1 == 0:\n",
    "        print('testing: ')\n",
    "        evaluate(model, test_edgeloader, multi_metrics=True)\n",
    "        print()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
